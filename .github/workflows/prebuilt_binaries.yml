on:
  workflow_call:
    inputs:
      platform:
        type: string
        required: false
        default: linux/amd64
      platform_base_image:
        required: false
        type: string
        default: amd64/almalinux:8
        description: The image to use as a base image when building the installer.
      build_cache:
        type: string
        required: false
      toolchain:
        required: true
        type: string
        description: The toolchain used to build the assets. The value is passed as build argument to Docker and used in tags and cache locations to distinguish different builds.
      environment:
        type: string
        required: false
    secrets:
      DOCKERHUB_USERNAME:
        required: true
      DOCKERHUB_READONLY_TOKEN:
        required: true

name: Pre-built binaries

jobs:
  build_installer:
    name: Build CUDA Quantum assets
    runs-on: ${{ (contains(inputs.platform, 'arm') && 'linux-arm64-cpu8') || 'linux-amd64-cpu8' }}
    permissions:
      contents: read
      packages: write
      id-token: write

    outputs:
      image_hash: ${{ steps.config.outputs.image_name }}@${{ steps.docker_build.outputs.digest }}
      artifact_name: ${{ steps.config.outputs.artifact_name }}

    environment:
      name: ${{ inputs.environment || 'default' }}
      url: ${{ vars.deployment_url || format('https://github.com/{0}', github.repository) }}

    # Needed for making local images available to the docker/build-push-action.
    # See also https://stackoverflow.com/a/63927832.
    services:
      registry:
        image: registry:2
        ports:
          - 5000:5000

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: Log in to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_READONLY_TOKEN }}

      - name: Login to GitHub CR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Configure build
        id: config
        run: |
          platform_tag=`echo ${{ inputs.platform }} | sed 's/linux\///g' | tr -d ' '`
          if ${{ github.ref_type == 'tag' || startsWith(github.ref_name, 'releases/') }}; then
            cudaq_version=`echo ${{ github.ref_name }} | egrep -o "([0-9]{1,}\.)+[0-9]{1,}"`
          else
            cudaq_version=0.0.0
          fi

          repo_owner=${{ github.repository_owner }}
          registry=${{ vars.registry || 'localhost:5000' }}
          image_name=$registry/${repo_owner,,}/cuda-quantum-assets
          tag_prefix=$platform_tag-${{ inputs.toolchain }}-

          if ${{ github.event.pull_request.merged == true }}; then
            tag_name=`echo ${{ github.event.pull_request.base.ref }} | tr / -`
            custom_tags="type=raw,value=${tag_name},priority=1000"
          elif ${{ startsWith(github.ref_name, 'pull-request/') }}; then
            pr_number=`echo ${{ github.ref_name }} | cut -d / -f2`
            custom_tags="type=raw,value=pr-${pr_number},priority=1000"
          fi

          registry_cache=`echo "${{ inputs.build_cache }}" | (egrep -o 'type=registry,ref=[a-zA-Z0-9_:/\.-]*' || echo)`
          registry_cache_image=`echo $registry_cache | rev | cut -d : -f2- | rev`

          echo "cudaq_version=$cudaq_version" >> $GITHUB_OUTPUT
          echo "image_name=$image_name" >> $GITHUB_OUTPUT
          echo "tag_prefix=$tag_prefix" >> $GITHUB_OUTPUT
          echo "custom_tags=$custom_tags" >> $GITHUB_OUTPUT
          echo "artifact_name=cudaq-${platform_tag}-installer-${{ github.run_id }}" >> $GITHUB_OUTPUT
          {
            echo 'additional_build_caches<<multiline'
            if ${{ github.event.pull_request.number != '' }}; then
              echo "$registry_cache_image::pull-request-${{ github.event.pull_request.number }}"
            elif [ -n "$registry_cache_image" ]; then
              echo "$registry_cache_image:$(echo ${{ github.ref_name }} | tr / -)"
            fi
            echo multiline
          } >> $GITHUB_OUTPUT

      - name: Set up context for buildx
        run: |
          docker context create builder_context

      - name: Set up buildx runner
        uses: docker/setup-buildx-action@v3
        with:
          endpoint: builder_context
          driver-opts: network=host

      - name: Extract metadata
        id: metadata
        uses: docker/metadata-action@v5
        with:
          images: ${{ steps.config.outputs.image_name }}
          flavor: |
            latest=false
            prefix=${{ steps.config.outputs.tag_prefix }},onlatest=true
          tags: |
            type=ref,enable=${{ steps.config.outputs.custom_tags == '' }},event=branch
            type=ref,enable=true,prefix=${{ steps.config.outputs.tag_prefix }}pr-,event=pr
            type=ref,enable=true,event=tag
            ${{ steps.config.outputs.custom_tags }}
          labels: |
            org.opencontainers.image.title=cuda-quantum-assets
            org.opencontainers.image.description=Pre-built Linux binaries for CUDA Quantum

      - name: Build assets
        id: docker_build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/build/assets.Dockerfile
          build-args: |
            release_version=${{ steps.config.outputs.cudaq_version }}
            base_image=${{ inputs.platform_base_image }}
          tags: ${{ steps.metadata.outputs.tags }}
          labels: ${{ steps.metadata.outputs.labels }}
          platforms: ${{ inputs.platform }}
          cache-from: |
            ${{ inputs.build_cache }}
            ${{ steps.config.outputs.additional_build_caches }}
          push: true

      - name: Install Cosign
        if: inputs.environment
        uses: sigstore/cosign-installer@v3.3.0
        with:
          cosign-release: 'v2.2.2'

      - name: Sign image with GitHub OIDC Token
        if: inputs.environment
        env:
          DIGEST: ${{ steps.docker_build.outputs.digest }}
          TAGS: ${{ steps.metadata.outputs.tags }}
        run: cosign sign --yes --recursive "${TAGS}@${DIGEST}"

      - name: Build installer
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/release/installer.Dockerfile
          build-args: |
            base_image=${{ steps.config.outputs.image_name }}@${{ steps.docker_build.outputs.digest }}
          platforms: ${{ inputs.platform }}
          outputs: type=local,dest=/tmp/install

      - name: Upload installer
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.config.outputs.artifact_name }}
          path: /tmp/install
          retention-days: 1
          if-no-files-found: error

  build_openmpi:
    name: Minimal OpenMPI installation
    runs-on: ${{ (contains(inputs.platform, 'arm') && 'linux-arm64-cpu8') || 'linux-amd64-cpu8' }}
    permissions:
      contents: read
      packages: write

    outputs:
      build_cache: ${{ steps.cache.outputs.build_cache }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure build
        id: cache
        run: |
          build_cache=`echo "${{ inputs.build_cache }}" | sed 's/prereqs/openmpi/g'`
          cache_to="${build_cache},mode=max,ignore-error=false"
          echo "cache_to=$cache_to" >> $GITHUB_OUTPUT
          echo "build_cache=$build_cache" >> $GITHUB_OUTPUT

      - name: Set up context for buildx
        run: |
          docker context create builder_context

      - name: Set up buildx runner
        uses: docker/setup-buildx-action@v3
        with:
          endpoint: builder_context

      - name: Log in to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_READONLY_TOKEN }}

      - name: Log in to GitHub CR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Build OpenMPI
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/test/installer/linux.Dockerfile
          target: mpibuild
          build-args: |
            base_image_mpibuild=${{ inputs.platform_base_image }}
          platforms: ${{ inputs.platform }}
          cache-from: |
            ${{ steps.cache.outputs.build_cache }}
          cache-to: ${{ steps.cache.outputs.cache_to }}
          # Do not push - the purpose of this is just to update the build cache

  create_test_config:
    name: Prepare validation
    runs-on: ubuntu-latest
    permissions:
      contents: read

    outputs:
      json: "${{ steps.config.outputs.json }}"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - id: config
        run: |
          config_file=".github/workflows/config/validation_config.json"
          cpp_config=`cat "$config_file" | jq '.cpp[] | select(.platform=="${{ inputs.platform }}")'`
          echo "json=$(echo $cpp_config)" >> $GITHUB_OUTPUT

  validation:
    name: Validate installer
    needs: [build_installer, build_openmpi, create_test_config]
    runs-on: ${{ (contains(inputs.platform, 'arm') && 'linux-arm64-cpu8') || 'linux-amd64-cpu8' }}
    permissions:
      contents: read
      packages: read

    strategy:
      matrix:
        os_image: ${{ fromJSON(needs.create_test_config.outputs.json).operating_systems }}
      fail-fast: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Log in to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_READONLY_TOKEN }}

      - name: Log in to GitHub CR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Load cuda-quantum installer
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.build_installer.outputs.artifact_name }}
          path: /tmp/install

      - name: Install in clean environment
        run: |
          config='${{ needs.create_test_config.outputs.json }}'
          system_config=`echo $config | jq -r '."${{ matrix.os_image }}"'`
          additional_build_args=`echo $system_config | jq 'to_entries[] | .key + "=" + (.value | tostring)'`
          mv /tmp/install/* .

          docker build -t validation:local -f "docker/test/installer/linux.Dockerfile" . \
            --cache-from ${{ needs.build_openmpi.outputs.build_cache }} \
            --build-arg cuda_quantum_installer=install_cuda_quantum.$(uname -m) \
            --build-arg cuda_quantum_wheel=cuda_quantum*$(uname -m).whl \
            --build-arg base_image=${{ matrix.os_image }} \
            --build-arg base_image_mpibuild=${{ inputs.platform_base_image }} \
            $(echo $additional_build_args | xargs | sed "s/[^ ]*/--build-arg &/g")

      - name: Sanity checks
        run: |
          docker run --rm -dit --name cuda-quantum validation:local
          (docker exec cuda-quantum bash -l validate.sh | tee /tmp/validation.out) && passed=true || passed=false
          docker stop cuda-quantum

          if ! $passed; then 
            echo "::error::Validation failed; see job summary for more details."
            exit 1
          fi

      - name: Side-by-side installation of Python support
        uses: ./.github/actions/run-in-docker
        with:
          image: validation:local
          user: cudaq
          shell: bash -l
          run: |
            PYTHON="python3.$(ls cuda_quantum*.whl | grep -o cp3[0-9]* | cut -c 4- | head -1)"
            if [ -x "$(command -v apt-get)" ]; then
              sudo apt-get update && sudo apt-get install -y --no-install-recommends $PYTHON $PYTHON-venv
              $PYTHON -m venv "$HOME/.venv" && PATH="$HOME/.venv/bin:$PATH"
            elif [ -x "$(command -v dnf)" ]; then
              sudo dnf install -y --nobest --setopt=install_weak_deps=False $(echo $PYTHON | tr -d .)
              $PYTHON -m ensurepip --upgrade
            elif [ -x "$(command -v zypper)" ]; then
              sudo zypper --non-interactive up --no-recommends
              sudo zypper --non-interactive in --no-recommends $(echo $PYTHON | tr -d .)
              $PYTHON -m ensurepip --upgrade            
            fi
            
            ${PYTHON} -m pip install cuda_quantum*.whl
            ${PYTHON} -m pip install pytest numpy
            ${PYTHON} -m pytest -v /home/cudaq/python \
              --ignore /home/cudaq/python/backends \
              --ignore /home/cudaq/python/domains
            if [ ! $? -eq 0 ]; then
              echo "::error file=prebuilt_binaries.yml::Sanity tests failed for side-by-side Python support."
              exit 1
            fi

      - name: Additional validation (MPI and uninstall)
        uses: ./.github/actions/run-in-docker
        with:
          image: validation:local
          user: cudaq
          shell: bash -l
          run: |
            # Uninstall CUDA Quantum
            install_dir="$CUDA_QUANTUM_PATH"
            sudo bash ${CUDA_QUANTUM_PATH}/uninstall.sh -y
            llvm_dir=`bash -c 'source configure_build.sh && echo $LLVM_INSTALL_PREFIX'`
            cuquantum_dir=`bash -c 'source configure_build.sh && echo $CUQUANTUM_INSTALL_PREFIX'`
            cutensor_dir=`bash -c 'source configure_build.sh && echo $CUTENSOR_INSTALL_PREFIX'`
            if [ -d "$llvm_dir" ] || [ -d "$cuquantum_dir" ] || [ -d "$cutensor_dir" ] ||  [ -d "$CUDA_QUANTUM_PATH" ]; then
              echo "::error::Some CUDA Quantum artifacts still exist after uninstalling."
              exit 100
            fi

            unset CUDA_QUANTUM_PATH && PATH=$(getconf PATH) && . /etc/profile
            if [ -n "$(bash -lc "echo $CUDA_QUANTUM_PATH")" ] || [ -n "$(bash -lc "echo $PATH | grep $install_dir")" ]; then 
              echo "::error::CUDA Quantum related settings are still contained in shell profile."
              exit 101
            fi

            # Re-install CUDA Quantum
            MPI_PATH=/usr/local/openmpi \
            sudo -E bash install_cuda_quantum.* --accept | tee install_log.txt
            if [ -n "$(cat install_log.txt | grep -i warning)" ]; then
              echo "::error::Re-installation produced a warning. Check the log for more detail."
              exit 102
            fi

            . /etc/profile
            set +e # Allow script to keep going through errors
            sudo bash /install_sshclient.sh
            status_sum=0

            if ${{ contains(matrix.os_image, 'redhat' ) }}; then
              sudo dnf install -y --nobest --setopt=install_weak_deps=False gcc-toolset-12
              source /opt/rh/gcc-toolset-12/enable
              export OMPI_CXX=g++
              /usr/local/openmpi/bin/mpic++ mpi_cuda_check.cpp -o check.x && \
              mpiexec -np 1 ./check.x
              status=$?
              if [ ! $status -eq 0 ]; then
                echo "MPI check for CUDA awareness failed."
                status_sum=$((status_sum+1))
              fi
            fi

            for ex in `find examples/other/distributed/ -name '*.cpp'`; do
              nvq++ -DCUDAQ_ENABLE_MPI_EXAMPLE=1 $ex
              status=$?
              if [ $status -eq 0 ]; then
                mpiexec -np 4 ./a.out
                status=$?
                filename=$(basename -- "$ex")
                if [ $status -eq 0 ]; then
                  echo "Successfully ran $filename."
                else
                  echo "Failed to execute $filename."
                  status_sum=$((status_sum+1))
                fi
              else
                echo "Compilation failed for $filename."
                status_sum=$((status_sum+1))
              fi
            done
            
            # Execute simple remote simulator tests with the installer 
            # because this target was skipped in validate.sh due to 
            # incomplete MPI installation (need install_sshclient.sh).
            for ex in `find examples/other/remote_sim/ -name '*.cpp'`; do
              nvq++ --target remote-mqpu $ex
              status=$?
              filename=$(basename -- "$ex")
              if [ $status -eq 0 ]; then
                ./a.out
                status=$?
                if [ $status -eq 0 ]; then
                  echo "Successfully ran $filename."
                else
                  echo "Failed to execute $filename."
                  status_sum=$((status_sum+1))
                fi
              else
                echo "Compilation failed for $filename."
                status_sum=$((status_sum+1))
              fi
            done

            set -e # Re-enable exit code error checking
            if [ ! $status_sum -eq 0 ]; then
              echo "::error::$status_sum examples failed; see the log for more detail."
              exit $status_sum
            fi

      - name: Create job summary
        if: always() && !cancelled()
        run: |
          if [ -f /tmp/validation.out ]; then
            echo "## Validation" >> $GITHUB_STEP_SUMMARY
            echo "The validation of the CUDA Quantum installation produced the following output:" >> $GITHUB_STEP_SUMMARY
            echo '```text' >> $GITHUB_STEP_SUMMARY
            cat /tmp/validation.out >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

  staging:
    name: Staging
    needs: [build_installer, build_openmpi, validation]
    if: inputs.environment
    runs-on: ubuntu-latest
    permissions: {}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create build info
        id: staging
        run: |
          image_hash=${{ needs.build_installer.outputs.image_hash }}
          platform_id=`echo "${{ inputs.platform }}" | sed 's/linux\///g' | tr -d ' ' | tr ',' -`
          echo "platform_id=$platform_id" >> $GITHUB_OUTPUT
          artifact_name=installer_${platform_id}_publishing # changing the artifact name requires updating other workflows
          echo "artifact_name=$artifact_name" >> $GITHUB_OUTPUT
          info_file="$artifact_name.txt"
          echo "info_file=$info_file" >> $GITHUB_OUTPUT

          mkdir -p "$(dirname "$info_file")" && rm -rf "$info_file"
          echo "source-sha: ${{ github.sha }}" >> "$info_file"
          echo "cuda-quantum-assets-image: $image_hash" >> "$info_file"
          echo "platform-base-image: ${{ inputs.platform_base_image }}" >> "$info_file"
          echo "openmpi-build-cache: ${{ needs.build_openmpi.outputs.build_cache }}" >> "$info_file"
          echo "platform: ${{ inputs.platform }}" >> "$info_file"
          cat .github/workflows/config/gitlab_commits.txt >> "$info_file"

      - name: Upload build info
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.staging.outputs.artifact_name }} # changing the artifact name requires updating other workflows
          path: ${{ steps.staging.outputs.info_file }}
          retention-days: 30
          if-no-files-found: error

  clean_up:
    name: Prepare cache clean-up
    needs: [build_installer, validation]
    # We need to clean up even if the workflow is cancelled or fails.
    if: always()
    runs-on: ubuntu-latest

    steps:
      - name: Delete artifacts
        uses: actions/github-script@v7
        with:
          script: |
            const res = await github.rest.actions.listArtifactsForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
            })

            res.data.artifacts
              .filter(({ name }) => name === '${{ needs.build_installer.outputs.artifact_name }}')
              .forEach(({ id }) => {
                github.rest.actions.deleteArtifact({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  artifact_id: id,
                })
              })