name: Nightly integration tests

concurrency:
  # only one integration tests workflow to be run at a time, since it involves pushing/cleaning up a test image (same tag).
  group: ${{ github.workflow }}${{ github.event.workflow_run.name }}
  cancel-in-progress: false

# Run on request and every day at 3 AM UTC
on:
  workflow_dispatch:
    inputs:
      target:
        description: 'Target (choose nightly to run like nightly tests)'
        required: true
        default: 'nightly'
        type: choice
        options:
          - nightly
          - anyon
          - fermioniq
          - infleqtion
          - ionq
          - iqm
          - oqc
          - orca
          - pasqal
          - qci
          - quantinuum
          - nvqc
      single_test_name:
        type: string
        required: false
        description: 'Single test (e.g., targettests/quantinuum/load_value.cpp). Runs default tests if left blank'
      target_machine:
        type: string
        required: false
        description: 'Target machine (e.g., H2-1E).'
      cudaq_test_image:
        type: string
        required: false
        default: '' # picked up from repo variable if not provided
        description: 'CUDA Quantum image to run the tests in. Default to the latest CUDA Quantum nightly image'
      commit_sha:
        type: string
        required: false
        description: 'Commit SHA to pull the code (examples/tests) for testing. Default to the commit associated with the CUDA Quantum docker image if left blank'
      cudaq_nvqc_deploy_image:
        type: string
        required: false
        default: '' # same as cudaq_test_image if not provided
        description: 'CUDA Quantum image to use for NVQC deployment to NVCF. Default to the latest CUDA Quantum nightly image'
      workflow_id:
        type: string
        required: false
        description: 'Workflow Id to retrieve the Python wheel for testing. Default to the wheels produced by the Publishing workflow associated with the latest nightly CUDA Quantum Docker image if left blank'
      python_version:
        type: choice
        required: true
        description: 'Python version to run wheel test'
        options:
        - '3.11'
        - '3.12'
        - '3.13'

  schedule:
    - cron: 0 3 * * *

env:
  NGC_QUANTUM_ORG: pnyjrcojiblh
  NGC_QUANTUM_TEAM: cuda-quantum
  NVQC_FUNCTION_ID: 3bfa0342-7d2a-4f1b-8e81-b6608d28ca7d
  # <Backend>:<GPU Type>:<Instance Type>:<Min Instances>:<Max Instances>
  NGC_NVQC_DEPLOYMENT_SPEC: GFN:L40S:gl40s_1.br25_2xlarge:1:1
  python_version: '3.12'

jobs:
  # We need this job purely to choose the container image values because the
  # `env` context is unavailable outside of "steps" contexts.
  setup:
    name: Configure jobs
    runs-on: ubuntu-latest
    permissions:
      packages: write

    environment:
      name: ghcr-deployment
      url: ${{ vars.deployment_url }}

    outputs:
      cudaq_test_image: ${{ steps.vars.outputs.cudaq_nightly_image }}@${{ steps.test_image.outputs.digest }}
      cudaq_nvqc_deploy_image: ${{ inputs.cudaq_nvqc_deploy_image || format('{0}@{1}', steps.vars.outputs.cudaq_nightly_image, steps.test_image.outputs.digest) }}

    steps:
      - name: Set variables
        id: vars
        run: |
          cudaq_test_image=${{ inputs.cudaq_test_image || vars.cudaq_test_image }}
          cudaq_nightly_image=ghcr.io/nvidia/${{ vars.packages_prefix }}cuda-quantum

          sudo apt-get update && sudo apt-get install -y --no-install-recommends curl
          curl -L https://github.com/regclient/regclient/releases/latest/download/regctl-linux-amd64 > regctl
          chmod 755 regctl

          manifest=`./regctl image manifest $cudaq_test_image --format "{{ json . }}"`
          platforms=`echo $manifest | jq -r '.manifests | map("\(.platform.os)/\(.platform.architecture)") | .[]'`
          echo "FROM $cudaq_test_image" >> test_image.Dockerfile

          echo "platforms=$(echo $platforms | tr ' ' ,)" >> $GITHUB_OUTPUT
          echo "cudaq_nightly_image=$cudaq_nightly_image" >> $GITHUB_OUTPUT

      - name: Log in to GitHub CR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Set up context for buildx
        run: |
          docker context create builder_context

      - name: Set up buildx runner
        uses: docker/setup-buildx-action@v3
        with:
          endpoint: builder_context
          version: v0.19.0
          driver-opts: |
            image=moby/buildkit:v0.19.0

      - name: Extract metadata
        id: metadata
        uses: docker/metadata-action@v5
        with:
          images: ${{ steps.vars.outputs.cudaq_nightly_image }}
          flavor: latest=false
          tags: type=raw,value=nightly
          labels: |
            org.opencontainers.image.title=cuda-quantum
            org.opencontainers.image.description=CUDA-Q image used for nightly integration tests

      - name: Update nightly image on GHCR
        id: test_image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: test_image.Dockerfile
          tags: ${{ steps.metadata.outputs.tags }}
          labels: ${{ steps.metadata.outputs.labels }}
          platforms: ${{ steps.vars.outputs.platforms }}
          push: true

  metadata:
    name: Retrieve commit info
    runs-on: ubuntu-latest
    needs: setup

    container:
      image: ${{ needs.setup.outputs.cudaq_test_image }}
      options: --user root
      credentials:
        username: ${{ github.actor }}
        password: ${{ github.token }}

    outputs:
      cudaq_commit: ${{ steps.commit-sha.outputs.sha }}

    steps:
      - name: Get commit SHA
        id: commit-sha
        run: |
          if [ -n "${{ inputs.commit_sha }}" ]; then
            echo "sha=${{ inputs.commit_sha }}" >> $GITHUB_OUTPUT
          else
            echo "sha=$(cat $CUDA_QUANTUM_PATH/build_info.txt | grep -o 'source-sha: \S*' | cut -d ' ' -f 2)" >> $GITHUB_OUTPUT
          fi

  build_nvqc_image:
    name: Build NVQC deployment image
    runs-on: ubuntu-latest
    if: (inputs.target == 'nvqc' || github.event_name == 'schedule' || inputs.target == 'nightly')
    needs: [setup, metadata]
    permissions:
      contents: read
      packages: write

    environment: ghcr-deployment

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.metadata.outputs.cudaq_commit }}
          fetch-depth: 1

      - name: Set up context for buildx
        run: |
          docker context create builder_context

      - name: Set up buildx runner
        uses: docker/setup-buildx-action@v3
        with:
          endpoint: builder_context
          version: v0.19.0
          driver-opts: |
            image=moby/buildkit:v0.19.0

      - name: Login to NGC container registry
        uses: docker/login-action@v3
        with:
          registry: nvcr.io
          username: '$oauthtoken'
          password: ${{ secrets.NGC_CREDENTIALS }}

      # Log in to GHCR (in case the base image is a local one)
      - name: Log in to the GitHub container registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Build NVQC image
        id: docker_build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/release/cudaq.nvqc.Dockerfile
          build-args: |
            base_image=${{ needs.setup.outputs.cudaq_nvqc_deploy_image }}
          tags: nvcr.io/${{ env.NGC_QUANTUM_ORG }}/${{ env.NGC_QUANTUM_TEAM }}/${{ vars.packages_prefix }}cuda-quantum:nightly
          platforms: linux/amd64
          provenance: false
          push: true

  deploy_nvqc_test_function:
    name: Deploy NVQC function
    runs-on: ubuntu-latest
    needs: [metadata, build_nvqc_image]
    if: (inputs.target == 'nvqc' || github.event_name == 'schedule' || inputs.target == 'nightly')
    permissions:
      contents: read

    # Must have environment protection
    environment: ghcr-deployment

    outputs:
      nvqc_function_version_id: ${{ steps.deploy.outputs.nvqc_function_version_id }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.metadata.outputs.cudaq_commit }}
          fetch-depth: 1

      - name: Install NGC CLI
        uses: ./.github/actions/install-ngc-cli
        with:
          version: 3.38.0
          checksum: 427c67684d792b673b63882a6d0cbb8777815095c0f2f31559c1570a91187388

      - name: Deploy NVQC Function
        id: deploy
        env:
          NGC_CLI_API_KEY: ${{ secrets.NGC_CREDENTIALS }}
          NGC_CLI_ORG: ${{ env.NGC_QUANTUM_ORG }}
          NGC_CLI_TEAM: cuda-quantum
        # When a new REST version is introduced, NVQC_REST_PAYLOAD_VERSION needs to be updated in lockstep with the new nightly CUDA Quantum image.
        # Otherwise, deployment of the test function will fail.
        run: |
          # We run with CUDAQ_SER_CODE_EXEC set. The final NVQC deployment may
          # or may not have this set, but since we run the client with
          # CUDAQ_CLIENT_REMOTE_CAPABILITY_OVERRIDE=1 (below), we need to run
          # the CI with CUDAQ_SER_CODE_EXEC=1. If we ever remove
          # CUDAQ_CLIENT_REMOTE_CAPABILITY_OVERRIDE=1 below, we can consider
          # removing CUDAQ_SER_CODE_EXEC=1.
          create_function_result=$(ngc-cli/ngc cloud-function function create \
            --container-image nvcr.io/${{ env.NGC_QUANTUM_ORG }}/${{ env.NGC_QUANTUM_TEAM }}/cuda-quantum:nightly \
            --container-environment-variable NUM_GPUS:1 \
            --container-environment-variable NVQC_REST_PAYLOAD_VERSION:1.1 \
            --container-environment-variable RUN_AS_NOBODY:1 \
            --container-environment-variable CUDAQ_SER_CODE_EXEC:1 \
            --api-body-format CUSTOM \
            --inference-port 3030 \
            --health-uri / \
            --inference-url /job \
            --name cudaq-nightly-integration-test \
            $NVQC_FUNCTION_ID)
          version_id=$(echo "$create_function_result" | grep 'Version: \S*' | head -1 | cut -d ':' -f 2 | tr -d ' ')
          echo "Create version Id: $version_id"
          echo "nvqc_function_version_id=$version_id" >> $GITHUB_OUTPUT
          # Deploy it
          ngc-cli/ngc cloud-function function deploy create --deployment-specification $NGC_NVQC_DEPLOYMENT_SPEC $NVQC_FUNCTION_ID:$version_id
          function_status=DEPLOYING
          while [ "$function_status" = "DEPLOYING" ]; do
            echo "Waiting for deploying NVQC function version $version_id ..."
            sleep 120
            function_info=$(ngc-cli/ngc cloud-function function info $NVQC_FUNCTION_ID:$version_id)
            function_status=$(echo "$function_info" | grep 'Status: \S*' | head -1 | cut -d ':' -f 2 | tr -d ' ')
          done
          if [ "$function_status" != "ACTIVE" ]; then
            echo "::error:: Failed to deploy NVQC Test Function"
            exit 1
          fi

  # Setup job to determine which providers to test
  provider_matrix_setup:
    name: Setup provider matrix
    runs-on: ubuntu-latest
    needs: [setup, metadata]
    outputs:
      providers: ${{ steps.set-matrix.outputs.providers }}
    steps:
      - name: Set provider matrix
        id: set-matrix
        run: |
          # Determine which providers to test based on inputs and event type
          if [[ "${{ github.event_name }}" == "schedule" || "${{ inputs.target }}" == "nightly" ]]; then
            providers='["anyon", "fermioniq", "infleqtion", "ionq", "iqm", "oqc", "orca", "pasqal", "qci", "quantinuum"]'
          else
            # Just run the specified target provider
            providers="[\"${{ inputs.target }}\"]"
          fi
          echo "providers=$providers" >> $GITHUB_OUTPUT

  # The parallel provider jobs using the matrix
  provider_test:
    name: Test ${{ matrix.provider }}
    needs: [setup, metadata, provider_matrix_setup]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        provider: ${{ fromJson(needs.provider_matrix_setup.outputs.providers) }}

    # Must have environment protection for the secrets
    environment: backend-validation
    container:
      image: ${{ needs.setup.outputs.cudaq_test_image }}
      options: --user root
      credentials:
        username: ${{ github.actor }}
        password: ${{ github.token }}

    steps:
      - name: Get code
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.metadata.outputs.cudaq_commit }}
          fetch-depth: 1

      - name: Get tests
        id: gettests
        run: |
          if [ -n "${{ inputs.single_test_name }}" ]; then
            if [ -e "${{ inputs.single_test_name }}" ]; then
              echo "testlist=${{ inputs.single_test_name }}" >> $GITHUB_OUTPUT
            else
              echo "::error::File ${{ inputs.single_test_name }} not found"
              exit 1
            fi
          else
            # Get tests specifically for this provider
            case "${{ matrix.provider }}" in
              anyon)
                filelist="targettests/anyon/*.cpp"
                ;;
              fermioniq)
                filelist="docs/sphinx/targets/cpp/fermioniq.cpp docs/sphinx/targets/python/fermioniq.py docs/sphinx/targets/python/fermioniq_observables.py"
                ;;
              infleqtion)
                filelist="docs/sphinx/targets/cpp/infleqtion.cpp docs/sphinx/targets/python/infleqtion.py"
                ;;
              ionq)
                filelist="targettests/ionq/*.cpp"
                ;;
              iqm)
                filelist="targettests/iqm/*.cpp"
                ;;
              oqc)
                filelist="targettests/oqc/*.cpp"
                ;;
              orca)
                filelist="docs/sphinx/targets/cpp/orca.cpp docs/sphinx/targets/cpp/orca_mqpu.cpp docs/sphinx/targets/python/orca.py docs/sphinx/targets/python/orca_mqpu.py"
                ;;
              pasqal)
                filelist="docs/sphinx/targets/cpp/pasqal.cpp docs/sphinx/targets/python/pasqal.py"
                ;;
              qci)
                filelist="targettests/qci/*.cpp"
                ;;
              quantinuum)
                # Include both legacy Quantinuum and Quantinuum-NG tests
                filelist="targettests/quantinuum/*.cpp targettests/quantinuum_ng/*.cpp docs/sphinx/targets/python/quantinuum.py"
                ;;
            esac
            echo "testlist=$filelist" >> $GITHUB_OUTPUT
          fi

      # Provider-specific setup steps
      - name: Setup ${{ matrix.provider }} account
        run: |
          case "${{ matrix.provider }}" in
            anyon)
              echo "### Setting up Anyon account" >> $GITHUB_STEP_SUMMARY
              echo "::add-mask::${{ secrets.ANYON_USERNAME }}"
              echo "::add-mask::${{ secrets.ANYON_PASSWORD }}"
              TEMP_NETRC=$(mktemp)
              chmod 600 "$TEMP_NETRC"
              printf "machine api.anyon.cloud\nlogin %s\npassword %s\n" "${{ secrets.ANYON_USERNAME }}" "${{ secrets.ANYON_PASSWORD }}" > "$TEMP_NETRC"
              response=$(curl -sS --netrc-file "$TEMP_NETRC" -X POST \
                -H "Content-Type: application/json" \
                https://api.anyon.cloud:5000/login 2>&1) || {
                echo "::error::Failed to authenticate with Anyon"
                rm -f "$TEMP_NETRC"
                exit 1
              }
              rm -f "$TEMP_NETRC"
              id_token=$(printf '%s' "$response" | jq -r '.id_token')
              refresh_token=$(printf '%s' "$response" | jq -r '.refresh_token')
              echo "::add-mask::$id_token"
              echo "::add-mask::$refresh_token"
              printf "key: %s\nrefresh: %s\n" "$id_token" "$refresh_token" > "$HOME/.anyon_config"
              chmod 600 "$HOME/.anyon_config"
              ;;
            fermioniq)
              echo "### Setting up Fermioniq account" >> $GITHUB_STEP_SUMMARY
              echo "::add-mask::${{ secrets.FERMIONIQ_ACCESS_TOKEN_ID }}"
              echo "::add-mask::${{ secrets.FERMIONIQ_ACCESS_TOKEN_SECRET }}"
              echo "FERMIONIQ_ACCESS_TOKEN_ID=${{ secrets.FERMIONIQ_ACCESS_TOKEN_ID }}" >> $GITHUB_ENV
              echo "FERMIONIQ_ACCESS_TOKEN_SECRET=${{ secrets.FERMIONIQ_ACCESS_TOKEN_SECRET }}" >> $GITHUB_ENV
              echo "FERMIONIQ_PROJECT_ID=c86e2cb8-d776-41ae-8240-d3d55e18b7c3" >> $GITHUB_ENV
              ;;
            infleqtion)
              echo "### Setting up Infleqtion account" >> $GITHUB_STEP_SUMMARY
              echo "::add-mask::${{ secrets.SUPERSTAQ_API_KEY }}"
              echo "SUPERSTAQ_API_KEY=${{ secrets.SUPERSTAQ_API_KEY }}" >> $GITHUB_ENV
              ;;
            ionq)
              echo "### Setting up IonQ account" >> $GITHUB_STEP_SUMMARY
              echo "::add-mask::${{ secrets.IONQ_API_KEY }}"
              echo "IONQ_API_KEY=${{ secrets.IONQ_API_KEY }}" >> $GITHUB_ENV
              ;;
            iqm)
              echo "### Setting up IQM account" >> $GITHUB_STEP_SUMMARY
              echo "::add-mask::${{ secrets.IQM_TOKEN }}"
              IQM_TOKEN_FILE="$(mktemp --suffix=.json)"
              printf '{ "access_token": "%s" }' "${{ secrets.IQM_TOKEN }}" > "$IQM_TOKEN_FILE"
              chmod 600 "$IQM_TOKEN_FILE"
              echo "IQM_TOKENS_FILE=$IQM_TOKEN_FILE" >> "$GITHUB_ENV"
              echo "IQM_SERVER_URL=https://cocos.resonance.meetiqm.com/pyrite:test" >> $GITHUB_ENV
              ;;
            oqc)
              echo "### Setting up OQC account" >> $GITHUB_STEP_SUMMARY
              echo "::add-mask::${{ secrets.OQC_URL }}"
              echo "::add-mask::${{ secrets.BACKEND_LOGIN_EMAIL }}"
              echo "::add-mask::${{ secrets.OQC_DEVICE }}"
              echo "::add-mask::${{ secrets.OQC_AUTH_TOKEN }}"
              echo "OQC_URL=${{ secrets.OQC_URL }}" >> $GITHUB_ENV
              echo "OQC_EMAIL=${{ secrets.BACKEND_LOGIN_EMAIL }}" >> $GITHUB_ENV
              echo "OQC_DEVICE=${{ secrets.OQC_DEVICE }}" >> $GITHUB_ENV
              echo "OQC_AUTH_TOKEN=${{ secrets.OQC_AUTH_TOKEN }}" >> $GITHUB_ENV
              ;;
            orca)
              echo "### Setting up ORCA account" >> $GITHUB_STEP_SUMMARY
              echo "::add-mask::${{ secrets.ORCA_ACCESS_URL }}"
              echo "ORCA_ACCESS_URL=${{ secrets.ORCA_ACCESS_URL }}" >> $GITHUB_ENV
              ;;
            pasqal)
              echo "### Setting up Pasqal account" >> $GITHUB_STEP_SUMMARY
              python3 -m pip install pasqal-cloud
              echo "::add-mask::${{ secrets.PASQAL_USERNAME }}"
              echo "::add-mask::${{ secrets.PASQAL_PASSWORD }}"
              echo "::add-mask::${{ secrets.PASQAL_PROJECT_ID }}"
              TEMP_SCRIPT=$(mktemp --suffix=.py)
              chmod 600 "$TEMP_SCRIPT"
              printf '%s\n' \
                "import os" \
                "import sys" \
                "from pasqal_cloud import SDK" \
                "try:" \
                "    sdk = SDK(username=os.environ['PASQAL_USER'], password=os.environ['PASQAL_PASS'])" \
                "    sys.stdout.write(str(sdk.user_token()))" \
                "except Exception as e:" \
                "    sys.stderr.write('Authentication failed\n')" \
                "    sys.exit(1)" > "$TEMP_SCRIPT"
              PASQAL_AUTH_TOKEN=$(PASQAL_USER="${{ secrets.PASQAL_USERNAME }}" \
                                  PASQAL_PASS="${{ secrets.PASQAL_PASSWORD }}" \
                                  python3 "$TEMP_SCRIPT" 2>/dev/null) || {
                echo "::error::Failed to authenticate with Pasqal"
                rm -f "$TEMP_SCRIPT"
                exit 1
              }
              rm -f "$TEMP_SCRIPT"
              echo "::add-mask::$PASQAL_AUTH_TOKEN"
              echo "PASQAL_AUTH_TOKEN=$PASQAL_AUTH_TOKEN" >> $GITHUB_ENV
              echo "PASQAL_USERNAME=${{ secrets.PASQAL_USERNAME }}" >> $GITHUB_ENV
              echo "PASQAL_PASSWORD=${{ secrets.PASQAL_PASSWORD }}" >> $GITHUB_ENV
              echo "PASQAL_PROJECT_ID=${{ secrets.PASQAL_PROJECT_ID }}" >> $GITHUB_ENV
              echo "PASQAL_MACHINE_TARGET=EMU_FREE" >> $GITHUB_ENV
              ;;
            qci)
              echo "### Setting up QCI account" >> $GITHUB_STEP_SUMMARY
              echo "::add-mask::${{ secrets.QCI_AUTH_TOKEN }}"
              echo "QCI_AUTH_TOKEN=${{ secrets.QCI_AUTH_TOKEN }}" >> $GITHUB_ENV
              ;;
            quantinuum)
              echo "### Setting up Quantinuum account" >> $GITHUB_STEP_SUMMARY
              echo "::add-mask::${{ secrets.BACKEND_LOGIN_EMAIL }}"
              echo "::add-mask::${{ secrets.QUANTINUUM_NEXUS_PASSWORD }}"
              curl -c ~/.quantinuum_cookies.txt -X POST https://nexus.quantinuum.com/auth/login -H "Content-Type: application/json" -d '{ "email":"${{ secrets.BACKEND_LOGIN_EMAIL }}","password":"${{ secrets.QUANTINUUM_NEXUS_PASSWORD }}" }' >/dev/null
              awk '$6 == "myqos_oat" {refresh=$7} $6 == "myqos_id" {key=$7} END {print "key: " key "\nrefresh: " refresh}' ~/.quantinuum_cookies.txt > ~/.quantinuum_config
              chmod 600 ~/.quantinuum_config
              rm ~/.quantinuum_cookies.txt
              ;;
          esac
        shell: bash

      # Run the provider-specific tests
      - name: Run tests for ${{ matrix.provider }}
        run: |
          echo "### Testing ${{ matrix.provider }}" >> $GITHUB_STEP_SUMMARY
          export CUDAQ_LOG_LEVEL="info"
          set +e # Allow script to keep going through errors
          test_err_sum=0
          test_skip_sum=0

          # Single loop handles both C++ and Python tests
          for filename in ${{ steps.gettests.outputs.testlist }}; do
            # Check if file exists
            if [ ! -e "$filename" ]; then
              echo "::warning::File not found: $filename"
              echo ":warning: Test skipped (file not found): $filename" >> $GITHUB_STEP_SUMMARY
              test_skip_sum=$((test_skip_sum+1))
              continue
            fi

            case "${{ matrix.provider }}" in
              anyon)
                nvq++ -v $filename -DSYNTAX_CHECK --target anyon --anyon-machine telegraph-8q
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  ./a.out
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
                ;;

              fermioniq)
                if [[ "$filename" == *.cpp ]]; then
                  nvq++ --target fermioniq --fermioniq-project-id $FERMIONIQ_PROJECT_ID $filename
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    ./a.out 1> /dev/null
                    test_status=$?
                    if [ $test_status -eq 0 ]; then
                      echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                    else
                      echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                      test_err_sum=$((test_err_sum+1))
                    fi
                  else
                    echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                elif [[ "$filename" == *.py ]]; then
                  python3 $filename 1> /dev/null
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo "::warning::Unsupported file type: $filename"
                  echo ":warning: Test skipped (unsupported file type): $filename" >> $GITHUB_STEP_SUMMARY
                  test_skip_sum=$((test_skip_sum+1))
                fi
                ;;

              infleqtion)
                if [[ "$filename" == *.cpp ]]; then
                  nvq++ --target infleqtion $filename
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    ./a.out
                    test_status=$?
                    if [ $test_status -eq 0 ]; then
                      echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                    else
                      echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                      test_err_sum=$((test_err_sum+1))
                    fi
                  else
                    echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                elif [[ "$filename" == *.py ]]; then
                  python3 $filename 1> /dev/null
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo "::warning::Unsupported file type: $filename"
                  echo ":warning: Test skipped (unsupported file type): $filename" >> $GITHUB_STEP_SUMMARY
                  test_skip_sum=$((test_skip_sum+1))
                fi
                ;;

              ionq)
                nvq++ -v $filename --target ionq
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  ./a.out
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
                ;;

              iqm)
                nvq++ -DSYNTAX_CHECK --target iqm $filename
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  ./a.out
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
                ;;

              oqc)
                nvq++ -DSYNTAX_CHECK --target oqc $filename
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  ./a.out
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
                ;;

              orca)
                if [[ "$filename" == *.cpp ]]; then
                  nvq++ --target orca --orca-url $ORCA_ACCESS_URL $filename
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    ./a.out
                    test_status=$?
                    if [ $test_status -eq 0 ]; then
                      echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                    else
                      echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                      test_err_sum=$((test_err_sum+1))
                    fi
                  else
                    echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                elif [[ "$filename" == *.py ]]; then
                  python3 $filename 1> /dev/null
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo "::warning::Unsupported file type: $filename"
                  echo ":warning: Test skipped (unsupported file type): $filename" >> $GITHUB_STEP_SUMMARY
                  test_skip_sum=$((test_skip_sum+1))
                fi
                ;;

              pasqal)
                if [[ "$filename" == *.cpp ]]; then
                  nvq++ --target pasqal --pasqal-machine $PASQAL_MACHINE_TARGET $filename
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    ./a.out 1> /dev/null
                    test_status=$?
                    if [ $test_status -eq 0 ]; then
                      echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                    else
                      echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                      test_err_sum=$((test_err_sum+1))
                    fi
                  else
                    echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                elif [[ "$filename" == *.py ]]; then
                  python3 $filename 1> /dev/null
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo "::warning::Unsupported file type: $filename"
                  echo ":warning: Test skipped (unsupported file type): $filename" >> $GITHUB_STEP_SUMMARY
                  test_skip_sum=$((test_skip_sum+1))
                fi
                ;;

              qci)
                nvq++ -v $filename --target qci
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  ./a.out
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
                ;;

              quantinuum)
                if [[ "$filename" == *.cpp ]]; then
                  if [[ "$filename" == *"quantinuum_ng/"* ]]; then
                    echo "### Running Quantinuum-NG test" >> $GITHUB_STEP_SUMMARY
                    nvq++ -v $filename --target quantinuum --quantinuum-machine Helios-1E --quantinuum-project ${{ secrets.QUANTINUUM_NEXUS_PROJECT_ID }} --quantinuum-max-cost 15 --quantinuum-max-qubits 7 --quantinuum-noisy-simulation false
                  else
                    echo "### Running standard Quantinuum test" >> $GITHUB_STEP_SUMMARY
                    nvq++ -v $filename -DSYNTAX_CHECK --target quantinuum --quantinuum-machine H2-1SC --quantinuum-project ${{ secrets.QUANTINUUM_NEXUS_PROJECT_ID }}
                  fi
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    ./a.out
                    test_status=$?
                    if [ $test_status -eq 0 ]; then
                      echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                    else
                      echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                      test_err_sum=$((test_err_sum+1))
                    fi
                  else
                    echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                elif [[ "$filename" == *.py ]]; then
                  echo "### Running Quantinuum Python test" >> $GITHUB_STEP_SUMMARY
                  QUANTINUUM_NEXUS_PROJECT=${{ secrets.QUANTINUUM_NEXUS_PROJECT_ID }} python3 $filename 1> /dev/null
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo "::warning::Unsupported file type: $filename"
                  echo ":warning: Test skipped (unsupported file type): $filename" >> $GITHUB_STEP_SUMMARY
                  test_skip_sum=$((test_skip_sum+1))
                fi
                ;;
            esac
          done

          # Print summary
          if [ $test_skip_sum -gt 0 ]; then
            echo "::warning::${test_skip_sum} tests skipped"
          fi

          set -e # Re-enable exit code error checking
          if [ ! $test_err_sum -eq 0 ]; then
            echo "::error::${test_err_sum} tests failed. See step summary for a list of failures"
            exit 1
          fi
          # Clean up
          rm -f "$HOME/.anyon_config" "$HOME/.quantinuum_config"
        shell: bash

  nvqc_integration_docker_test:
    name: NVQC integration test using Docker image
    runs-on: ubuntu-latest
    if: (inputs.target == 'nvqc' || github.event_name == 'schedule' || inputs.target == 'nightly')
    needs: [setup, metadata, build_nvqc_image, deploy_nvqc_test_function]
    permissions:
      contents: read
      packages: read

    # Must have environment protection
    environment:
      name: ghcr-deployment
      url: ${{ vars.deployment_url }}

    container:
      image: ${{ needs.setup.outputs.cudaq_test_image }}
      options: --user root
      credentials:
        username: ${{ github.actor }}
        password: ${{ github.token }}

    steps:
      - name: Skip NVQC Docker tests (temporary)
        id: skip_check
        run: |
          echo "### Submit to NVQC" >> $GITHUB_STEP_SUMMARY
          echo ":warning: NVQC Docker integration tests are temporarily skipped" >> $GITHUB_STEP_SUMMARY
          echo "::warning::NVQC Docker integration tests are temporarily skipped"
          echo "skipped=true" >> $GITHUB_OUTPUT
        shell: bash

      - name: Get code
        if: steps.skip_check.outputs.skipped != 'true'
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.metadata.outputs.cudaq_commit }}
          fetch-depth: 1

      - name: Submit to NVQC
        run: |
          echo "### Submit to NVQC" >> $GITHUB_STEP_SUMMARY
          export NVQC_API_KEY="${{ secrets.NVQC_SERVICE_KEY }}"
          export NVQC_FUNCTION_ID="$NVQC_FUNCTION_ID"
          export NVQC_FUNCTION_VERSION_ID="${{ needs.deploy_nvqc_test_function.outputs.nvqc_function_version_id }}"
          # When overriding the NVQC_FUNCTION_ID to a function that doesn't
          # follow the production naming convenvtions, we need to set the
          # following environment variable to tell the client that the server
          # has all the remote capabilities.
          export CUDAQ_CLIENT_REMOTE_CAPABILITY_OVERRIDE=1
          set +e # Allow script to keep going through errors
          test_err_sum=0
          # Test all NVQPP execution tests
          for filename in `find targettests/execution/ -name '*.cpp'`; do
            echo "$filename"
            # Only run tests that require execution (not a syntax-only check)
            if grep -q "ifndef SYNTAX_CHECK" "$filename"; then
              nvq++ -v $filename --target nvqc
              test_status=$?
              if [ $test_status -eq 0 ]; then
                ./a.out
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                else
                  echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              else
                echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                test_err_sum=$((test_err_sum+1))
              fi
            fi
          done

          # Test all remote-sim tests
          for filename in `find targettests/Remote-Sim -name '*.cpp'`; do
            # unsupport_args is compile error test
            # qvector_init_from_state, qvector_init_from_state_lazy, test_trotter: New argument synthesis is not executed for nvqc (https://github.com/NVIDIA/cuda-quantum/issues/2146)
            if [[ "$filename" != *"unsupport_args"* ]] && [[ "$filename" != *"qvector_init_from_state"* ]] && [[ "$filename" != *"qvector_init_from_state_lazy"* ]] && [[ "$filename" != *"test_trotter"* ]]; then
              echo "$filename"
              nvqc_config=""
              # Look for a --remote-mqpu-auto-launch to determine the number of QPUs
              num_qpus=`cat $filename | grep -oP -m 1 '^//\s*RUN:\s*nvq++.+--remote-mqpu-auto-launch\s+\K\S+'`
              if [ -n "$num_qpus" ]; then
                echo "Intended to run on '$num_qpus' QPUs."
                nvqc_config="$nvqc_config --nvqc-nqpus $num_qpus"
              fi
              nvq++ -v $filename --target nvqc $nvqc_config
              test_status=$?
              if [ $test_status -eq 0 ]; then
                ./a.out
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                else
                  echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
              fi
            fi
          done

          # Test C++ examples with NVQC
          for filename in `find examples/cpp/ applications/cpp/ targets/cpp/ -name '*.cpp'`; do
            if [[ "$filename" == *"nvqc"* ]]; then
              echo "$filename"
              nvqc_config=""
              # Look for a --nvqc-backend flag to nvq++ in the comment block
              nvqc_backend=`sed -e '/^$/,$d' $filename | grep -oP -m 1 '^//\s*nvq++.+--nvqc-backend\s+\K\S+'`
              if [ -n "$nvqc_backend" ]; then
                echo "Intended for execution on '$nvqc_backend' backend."
                nvqc_config="$nvqc_config --nvqc-backend $nvqc_backend"
              fi
              # Look for a --nvqc-nqpus flag to nvq++ in the comment block
              num_qpus=`sed -e '/^$/,$d' $filename | grep -oP -m 1 '^//\s*nvq++.+--nvqc-nqpus\s+\K\S+'`
              if [ -n "$num_qpus" ]; then
                echo "Intended to run on '$num_qpus' QPUs."
                nvqc_config="$nvqc_config --nvqc-nqpus $num_qpus"
              fi
              nvq++ -v $filename --target nvqc $nvqc_config
              test_status=$?
              if [ $test_status -eq 0 ]; then
                ./a.out
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                else
                  echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
              fi
            fi
          done

          # Test NVQC Python examples + Python MLIR execution tests (not IR tests)
          python3 -m pip install pytest
          for ex in `find examples/python python/tests/mlir/target -name '*.py'`; do
            filename=$(basename -- "$ex")
            filename="${filename%.*}"
            echo "Testing $filename:"
            if [[ "$ex" == *"nvqc"* ]]; then
              # This is an NVQC example
              python3 $ex 1> /dev/null
              test_status=$?
              if [ $test_status -eq 0 ]; then
                echo ":white_check_mark: Successfully ran test: $ex" >> $GITHUB_STEP_SUMMARY
              else
                echo ":x: Test failed (failed to execute): $ex" >> $GITHUB_STEP_SUMMARY
                test_err_sum=$((test_err_sum+1))
              fi
            # building_kernels.py is disabled due to https://github.com/NVIDIA/cuda-quantum/issues/2299.
            elif [[ "$ex" != *"building_kernels"* ]]; then
              # Only run examples that are not target-specific (e.g., ionq, iqm)
              if ! grep -q "set_target" "$ex"; then
                # Use --target command line option to run these examples with nvqc
                python3 $ex --target nvqc 1> /dev/null
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  echo ":white_check_mark: Successfully ran test: $ex" >> $GITHUB_STEP_SUMMARY
                else
                  echo ":x: Test failed (failed to execute): $ex" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              fi
            fi
          done

          set -e # Re-enable exit code error checking
          if [ ! $test_err_sum -eq 0 ]; then
            echo "::error::${test_err_sum} tests failed. See step summary for a list of failures"
            exit 1
          fi
        shell: bash

  nvqc_integration_wheel_test:
    name: NVQC integration test using Python wheels
    runs-on: ubuntu-latest
    if: inputs.target == 'nvqc' || github.event_name == 'schedule' || inputs.target == 'nightly'
    needs: [metadata, build_nvqc_image, deploy_nvqc_test_function]
    permissions:
      contents: read

    # Must have environment protection
    environment: ghcr-deployment

    steps:
      - name: Skip NVQC wheel tests (temporary)
        id: skip_check
        run: |
          echo "### Submit to NVQC from Python wheels" >> $GITHUB_STEP_SUMMARY
          echo ":warning: NVQC Python wheel integration tests are temporarily skipped" >> $GITHUB_STEP_SUMMARY
          echo "::warning::NVQC Python wheel integration tests are temporarily skipped"
          echo "skipped=true" >> $GITHUB_OUTPUT
        shell: bash

      - name: Get code
        if: steps.skip_check.outputs.skipped != 'true'
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.metadata.outputs.cudaq_commit }}
          fetch-depth: 1

      - name: Install wheel
        if: steps.skip_check.outputs.skipped != 'true'
        id: install_wheel
        run: |
          python_version=${{ inputs.python_version || env.python_version }}
          workflow_id=${{ inputs.workflow_id }}
          # Helper to get the *valid* Publishing run Id for a commit hash
          # Notes: runs that have 'CUDA-Q Python wheels' jobs skipped are not considered.
          function get_publishing_run_id {
            # Find all Publishing runs, we'll look into its jobs' status later
            if [[ -z "$1" ]]; then
              publishing_run_ids=$(gh run list --workflow Publishing --json databaseId --jq .[].databaseId)
            else
              publishing_run_ids=$(gh run list --commit $1 --workflow Publishing --json databaseId --jq .[].databaseId)
            fi
            for run_id in $publishing_run_ids ; do
                # Look into its jobs: if "CUDA-Q Python wheels" matrix build was performed,
                # then we have multiple jobs, like "CUDA-Q Python wheels (python_arm64....")
                cuda_wheel_build_jobs=$(gh run view $run_id --jq '.jobs.[] | select(.name | startswith("CUDA-Q Python wheels (python_")).name' --json jobs)
                if [ ! -z "$cuda_wheel_build_jobs" ]; then
                  # This is a valid run that produces wheel artifacts
                  echo $run_id
                  break
                fi
            done
          }

          if [ -z "${workflow_id}" ]; then
            workflow_id=$(get_publishing_run_id ${{ needs.metadata.outputs.cudaq_commit }})
          fi
          if [ ! -z "$workflow_id" ]; then
            echo "Using artifacts from workflow id $workflow_id"
            # Allow error when trying to download wheel artifacts since they might be expired.
            set +e
            gh run download $workflow_id --name "x86_64-cu12-py$python_version-wheels"
            retVal=$?
            set -e
            if [ $retVal -ne 0 ]; then
              echo "Failed to download wheels artifact from Publishing workflow run Id $workflow_id. Perhaps the artifacts have been expired."
              # This is allowed since there might be a period where no Publishing workflow is run (e.g., no PR merged to main).
              echo "skipped=true" >> $GITHUB_OUTPUT
              exit 0
            fi
            python_version_filename=$(echo "${python_version//.}")
            # Install Python and the wheel
            apt-get update && apt-get install -y --no-install-recommends python$python_version python3-pip
            wheelfile=$(find . -name "cuda_quantum_cu12*cp$python_version_filename*x86_64.whl")
            python$python_version -m pip install $wheelfile
            echo "skipped=false" >> $GITHUB_OUTPUT
          else
            echo "Failed to retrieve Publishing workflow run Id for commit ${{ needs.metadata.outputs.cudaq_commit }}"
            exit 1
          fi
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Test NVQC
        if: ${{ steps.skip_check.outputs.skipped != 'true' || steps.install_wheel.outputs.skipped != 'true' }}
        run: |
          echo "### Submit to NVQC from Python wheels" >> $GITHUB_STEP_SUMMARY
          python_version=${{ inputs.python_version || env.python_version }}
          export NVQC_API_KEY="${{ secrets.NVQC_SERVICE_KEY }}"
          export NVQC_FUNCTION_ID="$NVQC_FUNCTION_ID"
          export NVQC_FUNCTION_VERSION_ID="${{ needs.deploy_nvqc_test_function.outputs.nvqc_function_version_id }}"
          set +e # Allow script to keep going through errors
          python$python_version -m pip install pytest
          test_err_sum=0
          for ex in `find examples/python python/tests/mlir/target -name '*.py'`; do
            filename=$(basename -- "$ex")
            filename="${filename%.*}"
            echo "Testing $filename:"
            if [[ "$ex" == *"nvqc"* ]]; then
              python$python_version $ex 1> /dev/null
              test_status=$?
              if [ $test_status -eq 0 ]; then
                echo ":white_check_mark: Successfully ran test: $ex" >> $GITHUB_STEP_SUMMARY
              else
                echo ":x: Test failed (failed to execute): $ex" >> $GITHUB_STEP_SUMMARY
                test_err_sum=$((test_err_sum+1))
              fi
            # building_kernels.py is disabled due to https://github.com/NVIDIA/cuda-quantum/issues/2299.
            elif [[ "$ex" != *"building_kernels"* ]]; then
              # Only run examples that are not target-specific (e.g., ionq, iqm)
              if ! grep -q "set_target" "$ex"; then
                # Use --target command line option to run these examples with nvqc
                python$python_version $ex --target nvqc 1> /dev/null
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  echo ":white_check_mark: Successfully ran test: $ex" >> $GITHUB_STEP_SUMMARY
                else
                  echo ":x: Test failed (failed to execute): $ex" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              fi
            fi
          done
          set -e # Re-enable exit code error checking
          if [ ! $test_err_sum -eq 0 ]; then
            echo "::error::${test_err_sum} tests failed. See step summary for a list of failures"
            exit 1
          fi

  cleanup_nvqc_resources:
    name: Cleanup NVQC resources
    runs-on: ubuntu-latest
    if: (success() || failure()) && (inputs.target == 'nvqc' || github.event_name == 'schedule' || inputs.target == 'nightly')
    needs: [build_nvqc_image, deploy_nvqc_test_function, nvqc_integration_docker_test, nvqc_integration_wheel_test]
    permissions:
      contents: read

    # Must have environment protection
    environment: ghcr-deployment

    steps:
      - name: Get code
        uses: actions/checkout@v4

      - name: Install NGC CLI
        uses: ./.github/actions/install-ngc-cli
        with:
          version: 3.38.0
          checksum: 427c67684d792b673b63882a6d0cbb8777815095c0f2f31559c1570a91187388

      - name: Cleanup
        env:
          NGC_CLI_API_KEY: ${{ secrets.NGC_CREDENTIALS }}
          NGC_CLI_ORG: ${{ env.NGC_QUANTUM_ORG }}
          NGC_CLI_TEAM: cuda-quantum
        run: |
          echo "Version Id: ${{ needs.deploy_nvqc_test_function.outputs.nvqc_function_version_id }}"
          # Remove deployment (make it inactive)
          ngc-cli/ngc cloud-function function deploy remove $NVQC_FUNCTION_ID:${{ needs.deploy_nvqc_test_function.outputs.nvqc_function_version_id }}
          # Remove the function version
          ngc-cli/ngc cloud-function function remove $NVQC_FUNCTION_ID:${{ needs.deploy_nvqc_test_function.outputs.nvqc_function_version_id }}
          # Remove the docker image
          ngc-cli/ngc registry image remove -y nvcr.io/${{ env.NGC_QUANTUM_ORG }}/${{ env.NGC_QUANTUM_TEAM }}/cuda-quantum:nightly
