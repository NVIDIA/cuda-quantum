# ============================================================================ #
# Copyright (c) 2022 - 2024 NVIDIA Corporation & Affiliates.                   #
# All rights reserved.                                                         #
#                                                                              #
# This source code and the accompanying materials are made available under     #
# the terms of the Apache License 2.0 which accompanies this distribution.     #
# ============================================================================ #

name: "infleqtion"
description: "CUDA-Q target for Infleqtion."

config:
  # Tell DefaultQuantumPlatform what QPU subtype to use
  platform-qpu: remote_rest
  # Add the rest-qpu library to the link list
  link-libs: ["-lcudaq-rest-qpu"]
  # Tell NVQ++ to generate glue code to set the target backend name
  gen-target-backend: true
  # Define the lowering pipeline; # ADJUST DECOMPOSTION
  platform-lowering-config: "func.func(const-prop-complex,canonicalize,cse,lift-array-alloc),globalize-array-values,state-prep,unitary-synthesis,canonicalize,apply-op-specialization,aggressive-early-inlining,unrolling-pipeline,func.func(lower-to-cfg),canonicalize,func.func(multicontrol-decomposition),decomposition{enable-patterns=CCZToCZ,RxAdjToRx,RyAdjToRy,RzAdjToRz},func.func(memtoreg{quantum=0}),symbol-dce"
  # Tell the rest-qpu that we are generating OpenQASM 2.0.
  codegen-emission: qasm2
  # Library mode is only for simulators, physical backends must turn this off
  library-mode: false

target-arguments:
  - key: qpu
    required: false
    type: string
    platform-arg: qpu
    help-string: "Specify the Infleqtion QPU."
  - key: noise-model
    required: false
    type: string
    platform-arg: noise
    help-string: "Specify the noise model for simulation."