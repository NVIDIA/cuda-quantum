{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU Workflows\n",
    "\n",
    "There are many backends available with CUDA Quantum which enable seamless switching between GPUs, QPUs and CPUs and also allow for workflows involing multiple architectures working in tandem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target ionq\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target default\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=Default OpenMP CPU-only simulated QPU.\n",
      "\n",
      "Target nvidia-mqpu-fp64\n",
      "\tsimulator=custatevec_fp64\n",
      "\tplatform=mqpu\n",
      "\tdescription=The NVIDIA MQPU FP64 Target provides a simulated QPU for every available CUDA GPU on the underlying system. Each QPU is simulated via cuStateVec FP64.\n",
      "\n",
      "Target tensornet\n",
      "\tsimulator=tensornet\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target oqc\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target quantinuum\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target density-matrix-cpu\n",
      "\tsimulator=dm\n",
      "\tplatform=default\n",
      "\tdescription=The Density Matrix CPU Target provides a simulated QPU via OpenMP-enabled, CPU-only density matrix emulation.\n",
      "\n",
      "Target iqm\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target nvidia\n",
      "\tsimulator=custatevec_fp32\n",
      "\tplatform=default\n",
      "\tdescription=The NVIDIA Target provides a simulated QPU via single-GPU cuStateVec integration on FP32 types.\n",
      "\n",
      "Target nvidia-mqpu\n",
      "\tsimulator=custatevec_fp32\n",
      "\tplatform=mqpu\n",
      "\tdescription=The NVIDIA MQPU Target provides a simulated QPU for every available CUDA GPU on the underlying system. Each QPU is simulated via cuStateVec FP32. This target enables asynchronous parallel execution of quantum kernel tasks.\n",
      "\n",
      "Target nvidia-mgpu\n",
      "\tsimulator=nvidia_mgpu\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target nvidia-fp64\n",
      "\tsimulator=custatevec_fp64\n",
      "\tplatform=default\n",
      "\tdescription=The NVIDIA FP64 Target provides a simulated QPU via single-GPU cuStateVec integration on FP64 types.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "targets = cudaq.get_targets()\n",
    "\n",
    "for target in targets:\n",
    "     print(target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Targets\n",
    "\n",
    "- **default**: The default qpp based CPU backend which is multithreaded to maximise the usage of available cores on your system.\n",
    "\n",
    "- **nvidia**: GPU based backend which accelerates quantum circuit simulation on NVIDIA GPUs powered by cuQuantum.\n",
    "\n",
    "- **nvidia-mqpu**: Enables users to program workflows utilizing multiple quantum processors enabled today by GPU emulation. \n",
    "\n",
    "- **nvidia-mgpu**: Allows for scaling circuit simulation beyond what is feasible with any QPU today. \n",
    "\n",
    "- **density-matrix-cpu**: Noisy simulations via density matrix calculations. CPU only for now with GPU support coming soon. \n",
    "\n",
    "Below we explore how to effectively utilize multi-GPU targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ghz_state(qubit_count, target):\n",
    "    \"\"\"A function that will generate a variable sized GHZ state (`qubit_count`).\"\"\"\n",
    "    cudaq.set_target(target)\n",
    "\n",
    "    kernel = cudaq.make_kernel()\n",
    "\n",
    "    qubits = kernel.qalloc(qubit_count)\n",
    "\n",
    "    kernel.h(qubits[0])\n",
    "\n",
    "    for i in range(1, qubit_count):\n",
    "        kernel.cx(qubits[0], qubits[i])\n",
    "\n",
    "    kernel.mz(qubits)\n",
    "\n",
    "    result = cudaq.sample(kernel, shots_count=1000)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default CPU Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|00> : 498\n",
      "|11> : 502\n",
      "CPU times: user 1.05 s, sys: 4.25 ms, total: 1.05 s\n",
      "Wall time: 40.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cpu_result = ghz_state(qubit_count=2, target=\"default\")\n",
    "\n",
    "for state,value in cpu_result.items(): print(f'|{state}> : {value}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acceleration via NVIDIA GPUs\n",
    "\n",
    "Users will notice a **200x speedup** in executing the circuit below on NVIDIA GPUs vs CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|0000000000000000000000000> : 484\n",
      "|1111111111111111111111111> : 516\n",
      "CPU times: user 509 ms, sys: 384 ms, total: 893 ms\n",
      "Wall time: 918 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gpu_result = ghz_state(qubit_count=25, target=\"nvidia\")\n",
    "\n",
    "for state,value in gpu_result.items(): print(f'|{state}> : {value}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple NVIDIA GPUs\n",
    "\n",
    "A $n$ qubit quantum state has $2^n$ complex amplitudes, each of which require 8 bytes of memory to store. Hence the total memory required to store a $n$ qubit quantum state is $8$ bytes $\\times 2^n$. For $n = 30$ qubits, this is roughly $8$ GB but for $n = 40$, this exponentially increases to 8700 GB. \n",
    "\n",
    "If one incrementally increases the qubit count in their circuit, we reach a limit where the memory required is beyond the capabilities of a single GPU. The `nvidia-mgpu` target allows for memory from additional GPUs to be pooled enabling qubit counts to be scaled.  \n",
    "\n",
    "Execution on the `nvidia-mgpu` backed is enabled via `mpirun`. Users need to create a `.py` file with their code and run the command below in terminal:\n",
    "\n",
    "`mpirun -np 4 python3 test.py`\n",
    "\n",
    "where 4 is the number of GPUs one has access to and `test` is the file name chosen.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple QPU's\n",
    "\n",
    "The `nvidia-mqpu` backend allows for future workflows made possible via GPU simulation today. \n",
    "\n",
    "---\n",
    "\n",
    "### Asynchronous data collection via batching Hamiltonian terms\n",
    "\n",
    "Expectation value computations of multi-term hamiltonians can be asynchronously processed via the `mqpu` platform.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/hsplit.png\" alt=\"Alt Text\" width=\"500\" height=\"200\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaq.set_target(\"nvidia-mqpu\")\n",
    "\n",
    "qubit_count = 15\n",
    "term_count = 100000\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "\n",
    "qubits = kernel.qalloc(qubit_count)\n",
    "\n",
    "kernel.h(qubits[0])\n",
    "\n",
    "for i in range(1, qubit_count):\n",
    "    kernel.cx(qubits[0], qubits[i])\n",
    "\n",
    "# We create a random hamiltonian with 10e5 terms\n",
    "hamiltonian = cudaq.SpinOperator.random(qubit_count, term_count)\n",
    "\n",
    "# The observe calls allows us to calculate the expectation value of the Hamiltonian, batches the terms, and distributes them over the multiple QPU's/GPUs.\n",
    "\n",
    "# expectation = cudaq.observe(kernel, hamiltonian)  # Single node, single GPU.\n",
    "\n",
    "# Single node, multi-GPU.\n",
    "expectation = cudaq.observe(\n",
    "    kernel, hamiltonian,\n",
    "    execution=cudaq.parallel.thread\n",
    ")\n",
    "\n",
    "# expectation = cudaq.observe(kernel, hamiltonian, execution= cudaq.parallel.mpi) # Multi-node, multi-GPU."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> Asynchronous data collection via circuit batching</font>\n",
    "\n",
    "Execution of parameterized circuits with different parameters can be executed asynchronously via the `mqpu` platform.\n",
    "\n",
    "<img src=\"images/circsplit.png\" alt=\"Alt Text\" width=\"500\" height=\"200\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "cudaq.set_target(\"nvidia-mqpu\")\n",
    "\n",
    "qubit_count = 5\n",
    "sample_count = 10000\n",
    "h = spin.z(0)\n",
    "parameter_count = qubit_count\n",
    "\n",
    "# Below we run a circuit for 10000 different input parameters.\n",
    "parameters = (\n",
    "  np.random\n",
    "  .default_rng(13)\n",
    "  .uniform(\n",
    "    low=0,\n",
    "    high=1,\n",
    "    size=(sample_count,parameter_count)\n",
    "  )\n",
    ")\n",
    "\n",
    "kernel, params = cudaq.make_kernel(list)\n",
    "\n",
    "qubits = kernel.qalloc(qubit_count)\n",
    "qubits_list = list(range(qubit_count))\n",
    "\n",
    "for i in range(qubit_count):\n",
    "    kernel.rx(params[i], qubits[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.67 s, sys: 12.4 s, total: 16.1 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = cudaq.observe(kernel, h, parameters)   # Single GPU result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10000 parameters which we would like to execute\n",
      "This has been split this into 4 batches of 2500, 2500, 2500, 2500\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {parameters.shape[0]} parameters which we would like to execute')\n",
    "\n",
    "# We split our parameters into 4 arrays since we have 4 GPUs available.\n",
    "xi = np.split(parameters,4)  \n",
    "N  = [ _xi.shape[0] for _xi in xi ]\n",
    "print(f'This has been split this into {len(xi)} batches of {N[0]}, {N[1]}, {N[2]}, {N[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.39 s, sys: 1.88 s, total: 4.26 s\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Timing the execution on a single GPU vs 4 GPUs, users will see a 4x performance improvement\n",
    "\n",
    "asyncresults = []\n",
    "\n",
    "for i in range(len(xi)):\n",
    "    for j in range(xi[i].shape[0]):\n",
    "        asyncresults.append(\n",
    "            cudaq.observe_async(kernel, h, xi[i][j, :], qpu_id=i)\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA-Quantum-0.4.1",
   "language": "python",
   "name": "cuda-quantum-0.4.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
