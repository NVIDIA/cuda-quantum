{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "## PTSBE accuracy verification: noisy-reference XEB\n",
        "\n",
        "This notebook validates that the PTSBE (Pre-Trajectory Sampling with Batch Execution) noisy simulator produces correct measurement distributions by comparing against two independent references:\n",
        "\n",
        "1. **Density-matrix (DM) reference** (`density-matrix-cpu`): provides exact noisy outcome probabilities $p_{\\text{DM}}(x)$ via the full $2^n \\times 2^n$ density matrix diagonal. Used to compute the $F_{\\text{noisy}}$ metric.\n",
        "2. **Standard noisy sampler** (`nvidia`): performs native per-shot trajectory simulation through `cudaq.sample()` with noise. Scored against the same DM reference as a control.\n",
        "\n",
        "Histogram-based metrics like Hellinger fidelity break down at scale: with $D = 2^n$ possible bitstrings and a fixed shot budget $N$, most bins are empty once $n > 20$, so bin-by-bin comparisons are dominated by sampling noise. XEB avoids this by scoring each sample against the reference probability for that single outcome, giving an estimator that converges at $O(1/\\sqrt{N})$ regardless of $D$. For a detailed introduction to XEB theory, see [Google's XEB tutorial](https://quantumai.google/cirq/noise/qcvv/xeb_theory).\n",
        "\n",
        "We adapt Google's [cross-entropy benchmarking (XEB)](https://quantumai.google/cirq/noise/qcvv/xeb_theory) to work with a noisy reference distribution instead of an ideal statevector (we cannot rely on the Porter-Thomas distribution when our reference is noisy). The resulting metric, $F_{\\text{noisy}}$, directly measures whether a sampler draws from the same distribution as the DM reference.\n",
        "\n",
        "*Scalability note.* Computing $p_{\\text{DM}}(x)$ requires the exact diagonal of the $2^n \\times 2^n$ density matrix, which limits this approach to moderate qubit counts ($n \\le 12$ on CPU). For larger simulations, a sample-only metric like [Maximum Mean Discrepancy (MMD)](https://www.kaggle.com/code/onurtunali/maximum-mean-discrepancy) can compare the two sampling distributions directly, without access to exact probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {},
      "source": [
        "### Circuit family\n",
        "\n",
        "We use XEB-style random circuits following Google's structure ([Arute et al., Nature 2019](https://www.nature.com/articles/s41586-019-1666-5)). Each circuit has $n$ qubits arranged in a linear chain and $m$ depth cycles. One cycle consists of:\n",
        "\n",
        "- Single-qubit layer: A random gate from $\\{\\sqrt{X},\\, \\sqrt{Y},\\, \\sqrt{W}\\}$ applied to each qubit, where $W = (X + Y)/\\sqrt{2}$. No gate repeats on the same qubit in consecutive cycles.\n",
        "- Two-qubit layer: CX (CNOT) gates in an alternating nearest-neighbor tiling (even pairs on even cycles, odd pairs on odd cycles).\n",
        "\n",
        "This gate set produces distributions that are highly sensitive to per-gate errors, making it a strong probe for correctness. The implementation below uses the same three-gate set: $\\sqrt{X} = R_x(\\pi/2)$, $\\sqrt{Y} = R_y(\\pi/2)$, and $\\sqrt{W}$ decomposed as $R_z(\\pi/4)\\,R_x(\\pi/2)\\,R_z(-\\pi/4)$, with the no-consecutive-repeat constraint. CX (CNOT) substitutes for the native entangling gate.\n",
        "\n",
        "### Deriving the metric\n",
        "\n",
        "The linear XEB fidelity estimator from [Arute et al.](https://www.nature.com/articles/s41586-019-1666-5) ([Supplementary Information, Eq. 17](https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-019-1666-5/MediaObjects/41586_2019_1666_MOESM1_ESM.pdf)) relates the experimentally observed mean of $Dp_s(q) - 1$ to the fidelity $F$ and the sum of squared ideal probabilities:\n",
        "\n",
        "$$\\overline{\\langle Dp_s(q) - 1\\rangle} = F \\left(D\\sum_q p_s(q)^2 - 1\\right)$$\n",
        "\n",
        "Solving for $F$ and writing $e_U = \\sum_q p_s(q)^2$ and $\\hat{m}_U = \\frac{1}{N}\\sum_i p_s(x_i)$:\n",
        "\n",
        "$$F = \\frac{\\hat{m}_U - 1/D}{e_U - 1/D}$$\n",
        "\n",
        "In the standard setting, $p_s = p_{\\text{ideal}}$ and the Porter-Thomas distribution gives $e_U \\approx 2/D$, which simplifies the above to the familiar $F = D\\langle p_{\\text{ideal}}(x_i)\\rangle - 1$. We cannot use this simplification because our reference is a noisy mixed state whose diagonal is not Porter-Thomas distributed.\n",
        "\n",
        "We replace $p_s$ with $p_{\\text{DM}}(x) = \\langle x | \\rho | x \\rangle$, the diagonal of the density matrix from the trusted DM simulator. We then compute $e_U = \\sum_x p_{\\text{DM}}(x)^2$ exactly from the density matrix, with no distributional assumption:\n",
        "\n",
        "$$Z = \\sum_x p_{\\text{DM}}(x)^2$$\n",
        "\n",
        "The resulting metric is:\n",
        "\n",
        "$$F_{\\text{noisy}} = \\frac{\\hat{m}_U - 1/D}{Z - 1/D} = \\frac{\\frac{1}{N}\\sum_i p_{\\text{DM}}(x_i) \\;-\\; 1/D}{Z \\;-\\; 1/D} \\qquad \\text{where } D = 2^n$$\n",
        "\n",
        "- $F_{\\text{noisy}} = 1.0$: the PTSBE samples reproduce the exact noisy distribution ($\\hat{m}_U = Z$, i.e. the cross-correlation with the reference equals the reference's self-score).\n",
        "- $F_{\\text{noisy}} = 0.0$: the PTSBE samples are indistinguishable from uniform ($\\hat{m}_U = 1/D$).\n",
        "\n",
        "### Protocol\n",
        "\n",
        "For a random circuit $C$ drawn from the family above:\n",
        "\n",
        "1. **Reference probabilities**: Run $C$ with noise on `density-matrix-cpu`. Extract the diagonal of the final density matrix to get $p_{\\text{DM}}(x)$ for all $x \\in \\{0,1\\}^n$. Apply classical readout noise to match the measurement channel. Compute $Z = \\sum_x p_{\\text{DM}}(x)^2$.\n",
        "2. **Sample**: Run the same noisy circuit via both `cudaq.sample()` on cusvsim (control) and `cudaq.ptsbe.sample()` (test) to produce $N$ samples each.\n",
        "3. **Score**: For each sampler, compute $\\hat{m}_U = \\frac{1}{N}\\sum_i p_{\\text{DM}}(x_i)$ and $F_{\\text{noisy}} = (\\hat{m}_U - 1/D) / (Z - 1/D)$. Both should be $\\approx 1.0$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cell-2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cudaq loaded from: /home/talexander/Devel/cudaq-pstbe/vendor/cuda-quantum/build/python/cudaq\n",
            "GPU target:  nvidia\n",
            "DM target:   density-matrix-cpu\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "os.environ[\"OMP_NUM_THREADS\"] = str(os.cpu_count())\n",
        "\n",
        "# TODO: Remove this sys.path override before pushing the PR.\n",
        "sys.path.insert(0, os.path.expanduser(\n",
        "    \"~/Devel/cudaq-pstbe/vendor/cuda-quantum/build/python\"))\n",
        "\n",
        "import cudaq\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams.update({\n",
        "    \"figure.figsize\": (8, 4),\n",
        "    \"axes.grid\": True,\n",
        "    \"grid.alpha\": 0.3,\n",
        "})\n",
        "\n",
        "print(f\"cudaq loaded from: {cudaq.__path__[0]}\")\n",
        "assert hasattr(cudaq, \"ptsbe\"), \"cudaq.ptsbe not found -- is the build current?\"\n",
        "\n",
        "DM_TARGET = \"density-matrix-cpu\"\n",
        "\n",
        "# GPU state-vector target backed by cusvsim (cuStateVec).\n",
        "# cusvsim supports native per-shot trajectory noise simulation, so the same\n",
        "# backend serves both roles: PTSBE uses it for individual trajectory\n",
        "# state-vector evolution, and the standard sampler uses it for direct\n",
        "# noisy cudaq.sample().\n",
        "GPU_TARGET = \"nvidia\"\n",
        "try:\n",
        "    cudaq.set_target(GPU_TARGET)\n",
        "except Exception:\n",
        "    GPU_TARGET = \"qpp-cpu\"\n",
        "\n",
        "PTSBE_TARGET = GPU_TARGET\n",
        "STD_TARGET = GPU_TARGET\n",
        "\n",
        "cudaq.set_target(DM_TARGET)\n",
        "cudaq.set_random_seed(42)\n",
        "print(f\"GPU target:  {GPU_TARGET}\")\n",
        "print(f\"DM target:   {DM_TARGET}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": [
        "### Single-circuit walkthrough\n",
        "\n",
        "We walk through the full protocol on one fixed circuit ($n=8$, $m=8$), introducing each utility function as we need it.\n",
        "\n",
        "**Circuit construction.** `generate_gate_choices` draws gate IDs from $\\{\\sqrt{X},\\, \\sqrt{Y},\\, \\sqrt{W}\\}$ with a no-consecutive-repeat constraint. `build_xeb_circuit` assembles cycles of the chosen single-qubit gates followed by a nearest-neighbor CNOT chain. Pass `with_mz=False` for `get_state()` (no measurement collapse) and `with_mz=True` for `sample()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cell-4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3-qubit, depth-2 circuit (no noise): 8 unique bitstrings from 1000 shots\n",
            "{ 000:32 001:36 010:39 011:28 100:198 101:235 110:224 111:208 }\n",
            "\n"
          ]
        }
      ],
      "source": [
        "XEB_GATE_IDS = [0, 1, 2]  # sqrt(X), sqrt(Y), sqrt(W)\n",
        "\n",
        "\n",
        "def generate_gate_choices(n, depth, rng):\n",
        "    \"\"\"Generate per-qubit gate choices for an XEB circuit.\n",
        "\n",
        "    Returns an (n, depth) array of gate IDs from {0, 1, 2} corresponding to\n",
        "    {sqrt(X), sqrt(Y), sqrt(W)}.  Consecutive layers on the same qubit are\n",
        "    guaranteed to use different gates (matching the Arute et al. constraint).\n",
        "    \"\"\"\n",
        "    choices = np.empty((n, depth), dtype=int)\n",
        "    choices[:, 0] = rng.choice(XEB_GATE_IDS, size=n)\n",
        "    for d in range(1, depth):\n",
        "        for i in range(n):\n",
        "            prev = choices[i, d - 1]\n",
        "            choices[i, d] = rng.choice([g for g in XEB_GATE_IDS if g != prev])\n",
        "    return choices\n",
        "\n",
        "\n",
        "def _apply_xeb_gate(kernel, qubit, gate_id):\n",
        "    \"\"\"Apply one of {sqrt(X), sqrt(Y), sqrt(W)} to a qubit.\n",
        "\n",
        "    sqrt(X) = Rx(pi/2), sqrt(Y) = Ry(pi/2).\n",
        "    sqrt(W) with W = (X+Y)/sqrt(2) is a pi/2 rotation around the (1,1,0)\n",
        "    axis, decomposed as Rz(pi/4) Rx(pi/2) Rz(-pi/4).\n",
        "    \"\"\"\n",
        "    if gate_id == 0:\n",
        "        kernel.rx(np.pi / 2, qubit)\n",
        "    elif gate_id == 1:\n",
        "        kernel.ry(np.pi / 2, qubit)\n",
        "    else:\n",
        "        kernel.rz(np.pi / 4, qubit)\n",
        "        kernel.rx(np.pi / 2, qubit)\n",
        "        kernel.rz(-np.pi / 4, qubit)\n",
        "\n",
        "\n",
        "def build_xeb_circuit(n, depth, gate_choices, with_mz=True):\n",
        "    \"\"\"Build an XEB circuit following Arute et al. (2019).\n",
        "\n",
        "    Single-qubit layer: one of {sqrt(X), sqrt(Y), sqrt(W)} per qubit,\n",
        "    drawn with no consecutive repeats on any qubit.\n",
        "    Two-qubit layer: CX ladder across nearest neighbours.\n",
        "    \"\"\"\n",
        "    kernel = cudaq.make_kernel()\n",
        "    q = kernel.qalloc(n)\n",
        "    for d in range(depth):\n",
        "        for i in range(n):\n",
        "            _apply_xeb_gate(kernel, q[i], int(gate_choices[i, d]))\n",
        "        for i in range(n - 1):\n",
        "            kernel.cx(q[i], q[i + 1])\n",
        "    if with_mz:\n",
        "        kernel.mz(q)\n",
        "    return kernel\n",
        "\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "test_choices = generate_gate_choices(n=3, depth=2, rng=rng)\n",
        "test_kernel = build_xeb_circuit(3, 2, test_choices)\n",
        "counts = cudaq.sample(test_kernel, shots_count=1000)\n",
        "print(f\"3-qubit, depth-2 circuit (no noise): {len(counts)} unique bitstrings from 1000 shots\")\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {},
      "source": [
        "**Noise model.** PTSBE requires unitary-mixture noise channels (each Kraus operator is a scaled Pauli unitary). `build_noise_model` applies symmetric Pauli noise on single-qubit gates ($X/Y/Z$ each at $p_1/3$), two-qubit gates (15-term Pauli at $p_2/15$ each), and bit-flip readout error ($p_{\\text{meas}}$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cell-6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Same circuit with Pauli noise (p1=0.001, p2=0.01, p_meas=0.01):\n",
            "  8 unique bitstrings from 1000 shots\n",
            "{ 000:42 001:46 010:35 011:42 100:217 101:224 110:197 111:197 }\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def build_noise_model(p1=0.001, p2=0.01, p_meas=0.01):\n",
        "    \"\"\"Build a Pauli noise model with measurement readout error.\n",
        "\n",
        "    PTSBE requires unitary-mixture channels. Pauli channels satisfy this:\n",
        "    each Kraus operator is a Pauli unitary scaled by sqrt(p).\n",
        "    \"\"\"\n",
        "    noise = cudaq.NoiseModel()\n",
        "    pauli1 = cudaq.Pauli1([p1 / 3] * 3)\n",
        "    noise.add_all_qubit_channel('rx', pauli1)\n",
        "    noise.add_all_qubit_channel('ry', pauli1)\n",
        "    noise.add_all_qubit_channel('cx', cudaq.Pauli2([p2 / 15] * 15))\n",
        "    noise.add_all_qubit_channel('mz', cudaq.BitFlipChannel(p_meas))\n",
        "    return noise\n",
        "\n",
        "\n",
        "noise_model = build_noise_model()\n",
        "noisy_counts = cudaq.sample(test_kernel, noise_model=noise_model, shots_count=1000)\n",
        "print(f\"Same circuit with Pauli noise (p1=0.001, p2=0.01, p_meas=0.01):\")\n",
        "print(f\"  {len(noisy_counts)} unique bitstrings from 1000 shots\")\n",
        "print(noisy_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25ee9d8b",
      "metadata": {},
      "source": [
        "#### Density matrix reference\n",
        "\n",
        "We build both kernel variants (with and without measurement) from the same gate choices up front, ensuring both simulators run the exact same circuit. `get_dm_diagonal` takes the measurement-free kernel, runs it on `density-matrix-cpu` with noise, and extracts the diagonal $p_{\\text{DM}}(x) = \\langle x|\\rho|x\\rangle$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "68445659",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Circuit: n=8, depth=8\n",
            "D = 2^8 = 256\n",
            "Z = sum p_DM(x)^2 = 5.043771e-03\n",
            "Uniform baseline 1/D = 3.906250e-03\n",
            "Z - 1/D = 1.137521e-03\n",
            "Top 5 p_DM(x):\n",
            "  11010111  1.433727e-02\n",
            "  10111111  1.295116e-02\n",
            "  00110110  1.104876e-02\n",
            "  00101110  1.069331e-02\n",
            "  10100111  1.046053e-02\n"
          ]
        }
      ],
      "source": [
        "def _bit_reverse_permutation(n):\n",
        "    \"\"\"Return index array that maps MSB-ordered diagonal to LSB ordering.\"\"\"\n",
        "    D = 2 ** n\n",
        "    return np.array([int(f\"{i:0{n}b}\"[::-1], 2) for i in range(D)])\n",
        "\n",
        "\n",
        "def apply_readout_noise(probs, n, p_meas):\n",
        "    \"\"\"Apply per-qubit bit-flip measurement noise to a probability vector.\n",
        "\n",
        "    For each qubit, independently flips the measurement outcome with\n",
        "    probability p_meas.  This is the classical stochastic map\n",
        "    [[1-p, p], [p, 1-p]] applied along each qubit axis.\n",
        "    \"\"\"\n",
        "    if p_meas <= 0:\n",
        "        return probs.copy()\n",
        "    p = probs.reshape([2] * n).copy()\n",
        "    for q in range(n):\n",
        "        p0 = np.take(p, 0, axis=q)\n",
        "        p1 = np.take(p, 1, axis=q)\n",
        "        new_p0 = (1 - p_meas) * p0 + p_meas * p1\n",
        "        new_p1 = p_meas * p0 + (1 - p_meas) * p1\n",
        "        idx0 = [slice(None)] * n\n",
        "        idx0[q] = 0\n",
        "        idx1 = [slice(None)] * n\n",
        "        idx1[q] = 1\n",
        "        p[tuple(idx0)] = new_p0\n",
        "        p[tuple(idx1)] = new_p1\n",
        "    return p.flatten()\n",
        "\n",
        "\n",
        "def get_dm_diagonal(kernel, noise_model, n, p_meas=0.0):\n",
        "    \"\"\"Run DM simulation with noise and return the diagonal probabilities.\n",
        "\n",
        "    The density-matrix-cpu target (QPP) uses MSB qubit ordering. We permute\n",
        "    the diagonal to LSB ordering so indices match cudaq.sample() bitstrings.\n",
        "    If p_meas > 0, per-qubit bit-flip readout noise is applied classically.\n",
        "    \"\"\"\n",
        "    cudaq.set_target(DM_TARGET)\n",
        "    cudaq.set_noise(noise_model)\n",
        "    state = cudaq.get_state(kernel)\n",
        "    cudaq.unset_noise()\n",
        "    dm = np.array(state)\n",
        "    diag = np.real(np.diag(dm))\n",
        "    probs = diag[_bit_reverse_permutation(n)]\n",
        "    if p_meas > 0:\n",
        "        probs = apply_readout_noise(probs, n, p_meas)\n",
        "    return probs\n",
        "\n",
        "\n",
        "n, depth = 8, 8\n",
        "rng = np.random.default_rng(42)\n",
        "gate_choices = generate_gate_choices(n, depth, rng)\n",
        "noise_model = build_noise_model()\n",
        "D = 2 ** n\n",
        "\n",
        "kernel_no_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=False)\n",
        "kernel_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=True)\n",
        "\n",
        "p_dm = get_dm_diagonal(kernel_no_mz, noise_model, n, p_meas=0.01)\n",
        "Z = np.sum(p_dm ** 2)\n",
        "print(f\"Circuit: n={n}, depth={depth}\")\n",
        "print(f\"D = 2^{n} = {D}\")\n",
        "print(f\"Z = sum p_DM(x)^2 = {Z:.6e}\")\n",
        "print(f\"Uniform baseline 1/D = {1.0/D:.6e}\")\n",
        "print(f\"Z - 1/D = {Z - 1.0/D:.6e}\")\n",
        "top5_idx = np.argsort(p_dm)[::-1][:5]\n",
        "print(\"Top 5 p_DM(x):\")\n",
        "for idx in top5_idx:\n",
        "    print(f\"  {idx:0{n}b}  {p_dm[idx]:.6e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e402718a",
      "metadata": {},
      "source": [
        "#### Noisy sampling\n",
        "\n",
        "`run_noisy_sample` abstracts over the sampling backend. Both methods use the same GPU simulator (cusvsim) but through different code paths:\n",
        "\n",
        "- `method=\"standard\"`: `cudaq.sample()` on `STD_TARGET`. cusvsim performs native per-shot trajectory simulation internally.\n",
        "- `method=\"ptsbe\"`: `cudaq.ptsbe.sample()` on `PTSBE_TARGET`. PTSBE pre-generates a set of Kraus trajectories, then dispatches batched state-vector simulations on cusvsim.\n",
        "\n",
        "Any difference in $F_{\\text{noisy}}$ quantifies PTSBE's approximation error from trajectory truncation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b045b954",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "standard: 256 unique bitstrings, top 5: [('11010111', 1455), ('10111111', 1262), ('00101110', 1066), ('10100111', 1045), ('00110110', 1041)]\n",
            "   ptsbe: 256 unique bitstrings, top 5: [('11010111', 1804), ('10111111', 1664), ('00110110', 1325), ('10100111', 1264), ('00101110', 1251)]\n"
          ]
        }
      ],
      "source": [
        "def run_noisy_sample(kernel, noise_model, shots, method=\"ptsbe\",\n",
        "                     max_traj=1000, seed=42):\n",
        "    \"\"\"Sample a noisy circuit using either exact noisy simulation or PTSBE.\n",
        "\n",
        "    method=\"standard\" -- cudaq.sample() with noise on STD_TARGET\n",
        "    method=\"ptsbe\"    -- cudaq.ptsbe.sample() on PTSBE_TARGET\n",
        "    \"\"\"\n",
        "    if method == \"standard\":\n",
        "        cudaq.set_target(STD_TARGET)\n",
        "        return cudaq.sample(kernel, noise_model=noise_model, shots_count=shots)\n",
        "    elif method == \"ptsbe\":\n",
        "        cudaq.set_target(PTSBE_TARGET)\n",
        "        strategy = cudaq.ptsbe.ProbabilisticSamplingStrategy(seed=seed)\n",
        "        return cudaq.ptsbe.sample(\n",
        "            kernel, noise_model=noise_model, shots_count=shots,\n",
        "            sampling_strategy=strategy, max_trajectories=max_traj,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}\")\n",
        "\n",
        "\n",
        "N = 100_000\n",
        "for method in [\"standard\", \"ptsbe\"]:\n",
        "    result = run_noisy_sample(kernel_mz, noise_model, shots=N, method=method)\n",
        "    top5 = sorted(result.items(), key=lambda kv: kv[1], reverse=True)[:5]\n",
        "    print(f\"{method:>8s}: {len(result)} unique bitstrings, \"\n",
        "          f\"top 5: {[(bs, c) for bs, c in top5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62c2e74c",
      "metadata": {},
      "source": [
        "#### Scoring\n",
        "\n",
        "`compute_f_noisy` looks up $p_{\\text{DM}}(x_i)$ for each sampled bitstring, computes the mean $\\hat{m}_U$, and returns $F_{\\text{noisy}} = (\\hat{m}_U - 1/D) / (Z - 1/D)$. We score both `standard` (cusvsim trajectory simulation) and `ptsbe` side-by-side. `standard` should produce $F_{\\text{noisy}} \\approx 1.0$; PTSBE may show values slightly above 1.0 due to trajectory truncation bias (see **Trajectory convergence** in the calibration section)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3f359a3c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A/B comparison (n=8, depth=8, N=100000 shots):\n",
            "\n",
            "  standard: F_noisy = 0.9939, E = 5.036833e-03\n",
            "            top 5: [('11010111', 1441), ('10111111', 1266), ('00110110', 1084), ('01101100', 1072), ('00101110', 1045)]\n",
            "     ptsbe: F_noisy = 1.3706, E = 5.465351e-03\n",
            "            top 5: [('11010111', 1849), ('10111111', 1693), ('00110110', 1366), ('01101100', 1320), ('00101110', 1311)]\n"
          ]
        }
      ],
      "source": [
        "def compute_f_noisy(p_dm, result, n):\n",
        "    \"\"\"Compute noisy-reference XEB fidelity F_noisy.\"\"\"\n",
        "    D = 2 ** n\n",
        "    N = result.get_total_shots()\n",
        "    Z = np.sum(p_dm ** 2)\n",
        "    e = sum(count * p_dm[int(bs, 2)] for bs, count in result.items()) / N\n",
        "    f = (e - 1.0 / D) / (Z - 1.0 / D)\n",
        "    return f, e, Z\n",
        "\n",
        "\n",
        "N = 100_000\n",
        "print(f\"A/B comparison (n={n}, depth={depth}, N={N} shots):\\n\")\n",
        "for method in [\"standard\", \"ptsbe\"]:\n",
        "    result = run_noisy_sample(kernel_mz, noise_model, shots=N, method=method)\n",
        "    f, e, _ = compute_f_noisy(p_dm, result, n)\n",
        "    top5 = sorted(result.items(), key=lambda kv: kv[1], reverse=True)[:5]\n",
        "    print(f\"  {method:>8s}: F_noisy = {f:.4f}, E = {e:.6e}\")\n",
        "    print(f\"            top 5: {[(bs, c) for bs, c in top5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "calibration-header",
      "metadata": {},
      "source": [
        "### Calibration\n",
        "\n",
        "Before generating the main validation plots, we calibrate two parameters on a single circuit ($n=8$, depth $=8$):\n",
        "\n",
        "1. **Trajectory budget** (`MAX_TRAJ`): sweep `max_trajectories` and pick the smallest value where $F_{\\text{noisy}}$ falls within 0.01 of the standard (cusvsim) baseline. Cap at 5,000 if no point qualifies.\n",
        "2. **Shot budget** (`N_SHOTS`): sweep $N$ and pick the smallest value where run-to-run standard deviation drops below 0.005 (half the trajectory threshold, so shot noise does not mask bias). Cap at 500,000 if no point qualifies.\n",
        "\n",
        "The selected values flow into all downstream sweeps as `MAX_TRAJ` and `N_SHOTS`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-11",
      "metadata": {},
      "source": [
        "### Trajectory convergence\n",
        "\n",
        "$F_{\\text{noisy}}$ vs `max_trajectories` for a fixed circuit and fixed total shots. As the trajectory budget increases, PTSBE captures more of the total probability mass $P_S = \\sum_{k \\in S} p_k$ and $F_{\\text{noisy}}$ converges toward the standard sampler's baseline ($\\approx 1.0$). When $P_S < 1$, the selected (predominantly low-error) trajectories receive more weight than they should, making the output distribution artificially sharp and driving $F_{\\text{noisy}} > 1$.\n",
        "\n",
        "The table below reports `n_traj` (unique trajectories actually generated), `P_captured` ($P_S$), and `F_noisy` for each trajectory budget. This characterizes how many trajectories are needed for a given accuracy target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cell-12",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trajectory convergence (n=8, depth=8, N=100,000)\n",
            "\n",
            "              standard: F_noisy = 1.0037\n",
            "\n",
            "  max_traj    n_traj  P_captured   F_noisy\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "cudaq.ptsbe.sample() failed: no results stored for __global__",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m cudaq.set_target(PTSBE_TARGET)\n\u001b[32m     25\u001b[39m strategy = cudaq.ptsbe.ProbabilisticSamplingStrategy(seed=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m result = \u001b[43mcudaq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mptsbe\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkernel_mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnoise_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshots_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_trajectories\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_execution_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m trajs = result.ptsbe_execution_data.trajectories\n\u001b[32m     32\u001b[39m p_captured = \u001b[38;5;28msum\u001b[39m(t.probability \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m trajs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Devel/cudaq-pstbe/vendor/cuda-quantum/build/python/cudaq/runtime/ptsbe.py:118\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(kernel, shots_count, noise_model, max_trajectories, sampling_strategy, shot_allocation, return_execution_data, *args)\u001b[39m\n\u001b[32m    115\u001b[39m specMod, processedArgs = decorator.handle_call_arguments(*args)\n\u001b[32m    116\u001b[39m retTy = decorator.get_none_type()\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcudaq_runtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mptsbe\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecorator\u001b[49m\u001b[43m.\u001b[49m\u001b[43muniqName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecMod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretTy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mshots_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mmax_trajectories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mshot_allocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mreturn_execution_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43m*\u001b[49m\u001b[43mprocessedArgs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: cudaq.ptsbe.sample() failed: no results stored for __global__"
          ]
        }
      ],
      "source": [
        "n, depth = 8, 8\n",
        "N = 100_000\n",
        "rng = np.random.default_rng(200)\n",
        "gate_choices = generate_gate_choices(n, depth, rng)\n",
        "kernel_no_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=False)\n",
        "kernel_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=True)\n",
        "noise_model = build_noise_model()\n",
        "p_dm = get_dm_diagonal(kernel_no_mz, noise_model, n, p_meas=0.01)\n",
        "\n",
        "traj_counts = [25, 50, 100, 250, 500, 1000, 2000, 5000, 10000, 50000, 100000]\n",
        "TRAJ_MAX_CAP = 5_000\n",
        "TRAJ_THRESHOLD = 0.01\n",
        "\n",
        "result_std = run_noisy_sample(kernel_mz, noise_model, shots=N, method=\"standard\")\n",
        "f_std, _, _ = compute_f_noisy(p_dm, result_std, n)\n",
        "\n",
        "traj_f = []\n",
        "traj_n = []\n",
        "traj_pcap = []\n",
        "traj_mt_used = []\n",
        "print(f\"Trajectory convergence (n={n}, depth={depth}, N={N:,})\\n\")\n",
        "print(f\"  {'standard':>20s}: F_noisy = {f_std:.4f}\\n\")\n",
        "print(f\"{'max_traj':>10s}  {'n_traj':>8s}  {'P_captured':>10s}  {'F_noisy':>8s}\")\n",
        "for mt in traj_counts:\n",
        "    cudaq.set_target(PTSBE_TARGET)\n",
        "    strategy = cudaq.ptsbe.ProbabilisticSamplingStrategy(seed=42)\n",
        "    try:\n",
        "        result = cudaq.ptsbe.sample(\n",
        "            kernel_mz, noise_model=noise_model, shots_count=N,\n",
        "            sampling_strategy=strategy, max_trajectories=mt,\n",
        "            return_execution_data=True,\n",
        "        )\n",
        "    except RuntimeError as exc:\n",
        "        print(f\"{mt:>10d}  {'FAIL':>8s}  {'---':>10s}  {'---':>8s}  ({exc})\")\n",
        "        continue\n",
        "    trajs = result.ptsbe_execution_data.trajectories\n",
        "    p_captured = sum(t.probability for t in trajs)\n",
        "    n_traj = len(trajs)\n",
        "    f, _, _ = compute_f_noisy(p_dm, result, n)\n",
        "    traj_f.append(f)\n",
        "    traj_n.append(n_traj)\n",
        "    traj_pcap.append(p_captured)\n",
        "    traj_mt_used.append(mt)\n",
        "    print(f\"{mt:>10d}  {n_traj:>8d}  {p_captured:>10.6f}  {f:>8.4f}\")\n",
        "\n",
        "_selected_traj = None\n",
        "for mt, f in zip(traj_mt_used, traj_f):\n",
        "    if abs(f - f_std) < TRAJ_THRESHOLD:\n",
        "        _selected_traj = mt\n",
        "        break\n",
        "\n",
        "if _selected_traj is None:\n",
        "    _selected_traj = TRAJ_MAX_CAP\n",
        "    print(f\"\\n  ** No sweep point within {TRAJ_THRESHOLD} of standard baseline.\")\n",
        "    print(f\"  -> Capping MAX_TRAJ = {_selected_traj}\")\n",
        "else:\n",
        "    print(f\"\\n  -> Selected MAX_TRAJ = {_selected_traj}\"\n",
        "          f\"  (first within {TRAJ_THRESHOLD} of standard baseline)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2757536",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.semilogx(traj_mt_used, traj_f, \"o-\", label=\"ptsbe\")\n",
        "ax.axhline(f_std, color=\"C1\", ls=\"--\", label=f\"standard ({f_std:.3f})\")\n",
        "ax.axhline(1.0, color=\"k\", ls=\":\", lw=0.8)\n",
        "ax.set_xlabel(\"max_trajectories\")\n",
        "ax.set_ylabel(\"$F_{\\\\mathrm{noisy}}$\")\n",
        "ax.set_title(f\"Trajectory convergence (n={n}, depth={depth}, N={N:,})\")\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {},
      "source": [
        "### Shot convergence\n",
        "\n",
        "$F_{\\text{noisy}}$ vs number of shots $N$ for a fixed circuit using the trajectory budget selected above. Shows how many samples are needed for the metric itself to stabilize. Error bars from multiple runs at each $N$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-14",
      "metadata": {},
      "outputs": [],
      "source": [
        "n, depth = 8, 8\n",
        "max_traj = _selected_traj\n",
        "rng = np.random.default_rng(300)\n",
        "gate_choices = generate_gate_choices(n, depth, rng)\n",
        "kernel_no_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=False)\n",
        "kernel_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=True)\n",
        "noise_model = build_noise_model()\n",
        "p_dm = get_dm_diagonal(kernel_no_mz, noise_model, n, p_meas=0.01)\n",
        "\n",
        "shot_counts = [1_000, 5_000, 10_000, 50_000, 100_000, 500_000]\n",
        "SHOTS_MAX_CAP = 500_000\n",
        "SHOTS_STD_THRESHOLD = 0.005\n",
        "n_repeats = 3\n",
        "\n",
        "shot_conv = {m: {\"mean\": [], \"std\": []} for m in [\"standard\", \"ptsbe\"]}\n",
        "print(f\"Shot convergence (n={n}, depth={depth}, max_trajectories={max_traj})\")\n",
        "for N in shot_counts:\n",
        "    parts = []\n",
        "    for method in [\"standard\", \"ptsbe\"]:\n",
        "        f_values = []\n",
        "        for rep in range(n_repeats):\n",
        "            result = run_noisy_sample(kernel_mz, noise_model,\n",
        "                                      shots=N, max_traj=max_traj,\n",
        "                                      seed=400 + rep, method=method)\n",
        "            f, _, _ = compute_f_noisy(p_dm, result, n)\n",
        "            f_values.append(f)\n",
        "        shot_conv[method][\"mean\"].append(np.mean(f_values))\n",
        "        shot_conv[method][\"std\"].append(np.std(f_values))\n",
        "        parts.append(f\"{method}={np.mean(f_values):.4f}+/-{np.std(f_values):.4f}\")\n",
        "    print(f\"  N={N:>8d}:  {',  '.join(parts)}\")\n",
        "\n",
        "_selected_shots = None\n",
        "for sc, s in zip(shot_counts, shot_conv[\"ptsbe\"][\"std\"]):\n",
        "    if s < SHOTS_STD_THRESHOLD:\n",
        "        _selected_shots = sc\n",
        "        break\n",
        "\n",
        "if _selected_shots is None:\n",
        "    _selected_shots = SHOTS_MAX_CAP\n",
        "    print(f\"\\nNo sweep point with ptsbe std < {SHOTS_STD_THRESHOLD}.\")\n",
        "    print(f\"  Capping N_SHOTS = {_selected_shots:,}\")\n",
        "else:\n",
        "    print(f\"\\nSelected N_SHOTS = {_selected_shots:,}\"\n",
        "          f\"  (first with ptsbe std < {SHOTS_STD_THRESHOLD})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "536b0011",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "for method in [\"standard\", \"ptsbe\"]:\n",
        "    means = shot_conv[method][\"mean\"]\n",
        "    stds = shot_conv[method][\"std\"]\n",
        "    ax.errorbar(shot_counts, means, yerr=stds, marker=\"o\", capsize=3, label=method)\n",
        "ax.axhline(1.0, color=\"k\", ls=\":\", lw=0.8)\n",
        "ax.set_xscale(\"log\")\n",
        "ax.set_xlabel(\"Shots $N$\")\n",
        "ax.set_ylabel(\"$F_{\\\\mathrm{noisy}}$\")\n",
        "ax.set_title(f\"Shot convergence (n={n}, depth={depth}, max_traj={max_traj})\")\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aac55fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_TRAJ = _selected_traj\n",
        "N_SHOTS = _selected_shots\n",
        "print(f\"Calibrated parameters for all subsequent sections:\")\n",
        "print(f\"  MAX_TRAJ = {MAX_TRAJ}\")\n",
        "print(f\"  N_SHOTS  = {N_SHOTS:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "results-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## PTSBE validation results\n",
        "\n",
        "All sections below use the calibrated `MAX_TRAJ` and `N_SHOTS` selected above. If the threshold was not met within the sweep range, the parameter is capped at its maximum value and downstream results should be interpreted with that residual bias in mind."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-9",
      "metadata": {},
      "source": [
        "### Width/depth correctness sweep\n",
        "\n",
        "$F_{\\text{noisy}}$ vs depth for each width, using the calibrated `MAX_TRAJ` and `N_SHOTS`. The `standard` sampler should produce values tightly clustered near 1.0. PTSBE values may show slight bias from trajectory truncation.\n",
        "\n",
        "The CPU density-matrix simulator stores a $2^n \\times 2^n$ complex matrix, so practical limits are $n = 10$-$12$. The full test suite (in CI) should use $n$ up to 24 with GPU-backed simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-10",
      "metadata": {},
      "outputs": [],
      "source": [
        "widths = [4, 6, 8, 10]\n",
        "depths = [2, 4, 8]\n",
        "n_instances = 5\n",
        "N = N_SHOTS\n",
        "methods = [\"standard\", \"ptsbe\"]\n",
        "\n",
        "sweep_results = {m: {} for m in methods}\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "for n in widths:\n",
        "    noise_model = build_noise_model()\n",
        "    for depth in depths:\n",
        "        f_by_method = {m: [] for m in methods}\n",
        "        for inst in range(n_instances):\n",
        "            gate_choices = generate_gate_choices(n, depth, rng)\n",
        "            k_no_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=False)\n",
        "            k_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=True)\n",
        "            p_dm = get_dm_diagonal(k_no_mz, noise_model, n, p_meas=0.01)\n",
        "            for m in methods:\n",
        "                result = run_noisy_sample(k_mz, noise_model,\n",
        "                                          shots=N, max_traj=MAX_TRAJ, method=m)\n",
        "                f, _, _ = compute_f_noisy(p_dm, result, n)\n",
        "                f_by_method[m].append(f)\n",
        "        parts = []\n",
        "        for m in methods:\n",
        "            mean_f = np.mean(f_by_method[m])\n",
        "            std_f = np.std(f_by_method[m])\n",
        "            sweep_results[m][(n, depth)] = (mean_f, std_f)\n",
        "            parts.append(f\"{m}={mean_f:.4f}+/-{std_f:.4f}\")\n",
        "        print(f\"n={n:2d}, depth={depth:2d}:  {',  '.join(parts)}\")\n",
        "\n",
        "print()\n",
        "for m in methods:\n",
        "    vals = np.array([v[0] for v in sweep_results[m].values()])\n",
        "    print(f\"{m}: mean={vals.mean():.4f}, std={vals.std():.4f}, \"\n",
        "          f\"range=[{vals.min():.4f}, {vals.max():.4f}]\")\n",
        "std_ok = all(abs(v[0] - 1.0) < 0.05 for v in sweep_results[\"standard\"].values())\n",
        "print(f\"\\nstandard: all |F-1| < 0.05: {std_ok}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e042f52",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
        "for ax, method in zip(axes, [\"standard\", \"ptsbe\"]):\n",
        "    for w in widths:\n",
        "        ds = [d for d in depths if (w, d) in sweep_results[method]]\n",
        "        means = [sweep_results[method][(w, d)][0] for d in ds]\n",
        "        stds = [sweep_results[method][(w, d)][1] for d in ds]\n",
        "        ax.errorbar(ds, means, yerr=stds, marker=\"o\", capsize=3, label=f\"n={w}\")\n",
        "    ax.axhline(1.0, color=\"k\", ls=\"--\", lw=0.8)\n",
        "    ax.set_xlabel(\"Depth\")\n",
        "    ax.set_title(method)\n",
        "    ax.legend(fontsize=8)\n",
        "axes[0].set_ylabel(\"$F_{\\\\mathrm{noisy}}$\")\n",
        "fig.suptitle(\"Width/depth correctness sweep\", y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-15",
      "metadata": {},
      "source": [
        "### Noise strength sweep\n",
        "\n",
        "$F_{\\text{noisy}}$ vs single-qubit error rate $p_1$ for a fixed circuit. Both simulators use the same noise at each rate. $F_{\\text{noisy}}$ should stay near 1.0 across all rates, confirming the metric is not regime-dependent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-16",
      "metadata": {},
      "outputs": [],
      "source": [
        "n, depth = 8, 6\n",
        "rng = np.random.default_rng(500)\n",
        "gate_choices = generate_gate_choices(n, depth, rng)\n",
        "kernel_no_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=False)\n",
        "kernel_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=True)\n",
        "\n",
        "p1_values = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]\n",
        "\n",
        "noise_sweep = {m: [] for m in [\"standard\", \"ptsbe\"]}\n",
        "print(f\"Noise strength sweep (n={n}, depth={depth}, N={N_SHOTS:,})\")\n",
        "for p1 in p1_values:\n",
        "    p2 = p1 * 10\n",
        "    p_meas = p2\n",
        "    noise_model = build_noise_model(p1=p1, p2=p2, p_meas=p_meas)\n",
        "    p_dm = get_dm_diagonal(kernel_no_mz, noise_model, n, p_meas=p_meas)\n",
        "    parts = []\n",
        "    for method in [\"standard\", \"ptsbe\"]:\n",
        "        result = run_noisy_sample(kernel_mz, noise_model,\n",
        "                                  shots=N_SHOTS, max_traj=MAX_TRAJ, method=method)\n",
        "        f, _, Z = compute_f_noisy(p_dm, result, n)\n",
        "        noise_sweep[method].append(f)\n",
        "        parts.append(f\"{method}={f:.4f}\")\n",
        "    print(f\"  p1={p1:.4f}:  {',  '.join(parts)}  (Z={Z:.6e})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33e9a645",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "for method in [\"standard\", \"ptsbe\"]:\n",
        "    ax.semilogx(p1_values, noise_sweep[method], \"o-\", label=method)\n",
        "ax.axhline(1.0, color=\"k\", ls=\":\", lw=0.8)\n",
        "ax.set_xlabel(\"Single-qubit error rate $p_1$\")\n",
        "ax.set_ylabel(\"$F_{\\\\mathrm{noisy}}$\")\n",
        "ax.set_title(f\"Noise strength sweep (n={n}, depth={depth}, N={N:,})\")\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-17",
      "metadata": {},
      "source": [
        "### Performance comparison\n",
        "\n",
        "Wall-clock time vs number of shots for a fixed circuit. Both methods use the same GPU (cusvsim), but standard noisy sampling runs one trajectory per shot while PTSBE pre-generates trajectories and batches the state-vector simulations. The PTSBE advantage grows with shot count."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-18",
      "metadata": {},
      "outputs": [],
      "source": [
        "n, depth = 10, 8\n",
        "rng = np.random.default_rng(600)\n",
        "gate_choices = generate_gate_choices(n, depth, rng)\n",
        "noise_model = build_noise_model()\n",
        "kernel_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=True)\n",
        "\n",
        "perf_shots = [1_000, 10_000, 100_000, 1_000_000]\n",
        "perf_times = {\"standard\": [], \"ptsbe\": []}\n",
        "\n",
        "print(f\"Performance comparison (n={n}, depth={depth})\")\n",
        "print(f\"{'Shots':>10s}  {'Std (s)':>10s}  {'PTSBE (s)':>10s}  {'Speedup':>8s}\")\n",
        "for N in perf_shots:\n",
        "    t0 = time.perf_counter()\n",
        "    run_noisy_sample(kernel_mz, noise_model, shots=N, method=\"standard\")\n",
        "    t_std = time.perf_counter() - t0\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    run_noisy_sample(kernel_mz, noise_model, shots=N, max_traj=MAX_TRAJ, method=\"ptsbe\")\n",
        "    t_ptsbe = time.perf_counter() - t0\n",
        "\n",
        "    perf_times[\"standard\"].append(t_std)\n",
        "    perf_times[\"ptsbe\"].append(t_ptsbe)\n",
        "    speedup = t_std / t_ptsbe if t_ptsbe > 0 else float('inf')\n",
        "    print(f\"{N:>10d}  {t_std:>10.3f}  {t_ptsbe:>10.3f}  {speedup:>7.1f}x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "125e482b",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "for method in [\"standard\", \"ptsbe\"]:\n",
        "    ax.loglog(perf_shots, perf_times[method], \"o-\", label=method)\n",
        "ax.set_xlabel(\"Shots\")\n",
        "ax.set_ylabel(\"Wall-clock time (s)\")\n",
        "ax.set_title(f\"Performance: standard vs PTSBE (n={n}, depth={depth})\")\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-19",
      "metadata": {},
      "source": [
        "### Summary\n",
        "\n",
        "Aggregate $F_{\\text{noisy}}$ statistics from the width/depth sweep using the calibrated `MAX_TRAJ` and `N_SHOTS`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-20",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"F_noisy distribution across all (n, depth) pairs:\\n\")\n",
        "for method in [\"standard\", \"ptsbe\"]:\n",
        "    vals = [v[0] for v in sweep_results[method].values()]\n",
        "    f_arr = np.array(vals)\n",
        "    print(f\"  {method}:\")\n",
        "    print(f\"    Mean:   {f_arr.mean():.4f}\")\n",
        "    print(f\"    Std:    {f_arr.std():.4f}\")\n",
        "    print(f\"    Range:  [{f_arr.min():.4f}, {f_arr.max():.4f}]\")\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "for method in [\"standard\", \"ptsbe\"]:\n",
        "    vals = [v[0] for v in sweep_results[method].values()]\n",
        "    ax.hist(vals, bins=15, alpha=0.6, label=method, edgecolor=\"white\")\n",
        "ax.axvline(1.0, color=\"k\", ls=\"--\", lw=0.8, label=\"ideal\")\n",
        "ax.set_xlabel(\"$F_{\\\\mathrm{noisy}}$\")\n",
        "ax.set_ylabel(\"Count\")\n",
        "ax.set_title(\"Distribution of $F_{\\\\mathrm{noisy}}$ across width/depth sweep\")\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "metric-validation-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Metric validation\n",
        "\n",
        "The sections above establish that PTSBE produces correct noisy distributions. The sections below validate the $F_{\\text{noisy}}$ metric itself: that it has discriminating power (negative control) and that we understand the source of any bias (trajectory truncation)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {},
      "source": [
        "### Negative control\n",
        "\n",
        "Demonstrate that $F_{\\text{noisy}}$ detects trajectory selection bias in PTSBE. We compare three sampling strategies at the same `max_trajectories` budget:\n",
        "\n",
        "- **standard**: exact noisy sampling via `STD_TARGET` (baseline, $F_{\\text{noisy}} \\approx 1.0$).\n",
        "- **Probabilistic**: `ProbabilisticSamplingStrategy` draws trajectories randomly weighted by probability. This is the default and should approximate the true noisy distribution well.\n",
        "- **Ordered**: `OrderedSamplingStrategy` deterministically selects the top-k highest-probability trajectories, systematically excluding high-error paths. This makes the output distribution artificially sharp and should drive $F_{\\text{noisy}}$ above 1.0.\n",
        "\n",
        "A metric with discriminating power must clearly separate the ordered case from the other two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {},
      "outputs": [],
      "source": [
        "n, depth = 8, 8\n",
        "rng = np.random.default_rng(100)\n",
        "gate_choices = generate_gate_choices(n, depth, rng)\n",
        "kernel_no_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=False)\n",
        "kernel_mz = build_xeb_circuit(n, depth, gate_choices, with_mz=True)\n",
        "\n",
        "noise_model = build_noise_model()\n",
        "p_dm = get_dm_diagonal(kernel_no_mz, noise_model, n, p_meas=0.01)\n",
        "\n",
        "neg_ctrl = {}\n",
        "\n",
        "result_std = run_noisy_sample(kernel_mz, noise_model, shots=N_SHOTS, method=\"standard\")\n",
        "f_std, _, _ = compute_f_noisy(p_dm, result_std, n)\n",
        "neg_ctrl[\"standard\"] = f_std\n",
        "\n",
        "strategies = {\n",
        "    \"Probabilistic\": cudaq.ptsbe.ProbabilisticSamplingStrategy(seed=42),\n",
        "    \"Ordered\": cudaq.ptsbe.OrderedSamplingStrategy(),\n",
        "}\n",
        "\n",
        "print(f\"Negative control (n={n}, depth={depth}, N={N_SHOTS:,}, max_traj={MAX_TRAJ})\\n\")\n",
        "print(f\"  {'standard':>16s}: F_noisy = {f_std:.4f}\")\n",
        "for label, strategy in strategies.items():\n",
        "    cudaq.set_target(PTSBE_TARGET)\n",
        "    result = cudaq.ptsbe.sample(\n",
        "        kernel_mz, noise_model=noise_model, shots_count=N_SHOTS,\n",
        "        sampling_strategy=strategy, max_trajectories=MAX_TRAJ,\n",
        "    )\n",
        "    f, _, _ = compute_f_noisy(p_dm, result, n)\n",
        "    neg_ctrl[label] = f\n",
        "    print(f\"  {label:>16s}: F_noisy = {f:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "197dfbcf",
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = list(neg_ctrl.keys())\n",
        "vals = list(neg_ctrl.values())\n",
        "colors = [\"C0\", \"C1\", \"C3\"]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bars = ax.bar(labels, vals, color=colors)\n",
        "ax.axhline(1.0, color=\"k\", ls=\"--\", lw=0.8)\n",
        "for bar, v in zip(bars, vals):\n",
        "    ax.text(bar.get_x() + bar.get_width() / 2, v + 0.02,\n",
        "            f\"{v:.3f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
        "ax.set_ylabel(\"$F_{\\\\mathrm{noisy}}$\")\n",
        "ax.set_title(f\"Negative control: sampling strategy comparison (max_traj={MAX_TRAJ})\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f07c4e6f",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
