// ========================================================================== //
// Copyright (c) 2022 - 2025 NVIDIA Corporation & Affiliates.                 //
// All rights reserved.                                                       //
//                                                                            //
// This source code and the accompanying materials are made available under   //
// the terms of the Apache License 2.0 which accompanies this distribution.   //
// ========================================================================== //

// RUN: cudaq-opt  -cc-loop-unroll %s | FileCheck %s
func.func @__nvqpp__mlirgen__test_loop_unroll() attributes {"cudaq-entrypoint", "cudaq-kernel"} {
  %c1_i64 = arith.constant 1 : i64
  %c2_i64 = arith.constant 2 : i64
  %c0_i64 = arith.constant 0 : i64
  %0 = quake.alloca !quake.veq<6>
  %1 = quake.extract_ref %0[0] : (!quake.veq<6>) -> !quake.ref
  quake.x %1 : (!quake.ref) -> ()
  %2 = cc.alloca i64
  cc.store %c2_i64, %2 : !cc.ptr<i64>
  %3 = cc.load %2 : !cc.ptr<i64>
  %4 = math.absi %3 : i64
  %5 = cc.alloca i64[%4 : i64]
  %6 = cc.alloca i64
  cc.store %c0_i64, %6 : !cc.ptr<i64>
  %7 = cc.loop while ((%arg0 = %c0_i64) -> (i64)) {
    %44 = arith.cmpi slt, %arg0, %3 : i64
    cc.condition %44(%arg0 : i64)
  } do {
  ^bb0(%arg0: i64):
    %44 = cc.load %6 : !cc.ptr<i64>
    %45 = cc.compute_ptr %5[%44] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
    cc.store %44, %45 : !cc.ptr<i64>
    %46 = arith.addi %44, %c1_i64 : i64
    cc.store %46, %6 : !cc.ptr<i64>
    cc.continue %arg0 : i64
  } step {
  ^bb0(%arg0: i64):
    %44 = arith.addi %arg0, %c1_i64 : i64
    cc.continue %44 : i64
  } {invariant}
  %8 = cc.alloca i64[%3 : i64]
  %9 = cc.loop while ((%arg0 = %c0_i64) -> (i64)) {
    %44 = arith.cmpi slt, %arg0, %3 : i64
    cc.condition %44(%arg0 : i64)
  } do {
  ^bb0(%arg0: i64):
    %44 = cc.compute_ptr %5[%arg0] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
    %45 = cc.load %44 : !cc.ptr<i64>
    %46 = arith.muli %45, %c2_i64 : i64
    %47 = cc.compute_ptr %8[%arg0] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
    cc.store %46, %47 : !cc.ptr<i64>
    cc.continue %arg0 : i64
  } step {
  ^bb0(%arg0: i64):
    %44 = arith.addi %arg0, %c1_i64 : i64
    cc.continue %44 : i64
  } {invariant}
  %10 = cc.stdvec_init %8, %3 : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.stdvec<i64>
  %11 = cc.alloca !cc.stdvec<i64>
  cc.store %10, %11 : !cc.ptr<!cc.stdvec<i64>>
  %12 = cc.load %11 : !cc.ptr<!cc.stdvec<i64>>
  %13 = cc.stdvec_size %12 : (!cc.stdvec<i64>) -> i64
  %14 = cc.alloca i64
  cc.store %13, %14 : !cc.ptr<i64>
  %15 = cc.alloca i64
  cc.store %c0_i64, %15 : !cc.ptr<i64>
  %16 = cc.alloca i64
  cc.store %c0_i64, %16 : !cc.ptr<i64>
  %17 = cc.load %14 : !cc.ptr<i64>
  %18 = arith.subi %17, %c1_i64 : i64
  %19 = cc.loop while ((%arg0 = %c0_i64) -> (i64)) {
    %44 = arith.cmpi slt, %arg0, %18 : i64
    cc.condition %44(%arg0 : i64)
  } do {
  ^bb0(%arg0: i64):
    %44 = arith.addi %arg0, %c1_i64 : i64
    %45 = cc.load %14 : !cc.ptr<i64>
    %46 = cc.loop while ((%arg1 = %44) -> (i64)) {
      %47 = arith.cmpi slt, %arg1, %45 : i64
      cc.condition %47(%arg1 : i64)
    } do {
    ^bb0(%arg1: i64):
      %47 = cc.load %16 : !cc.ptr<i64>
      %48 = arith.addi %47, %c1_i64 : i64
      cc.store %48, %16 : !cc.ptr<i64>
      cc.continue %arg1 : i64
    } step {
    ^bb0(%arg1: i64):
      %47 = arith.addi %arg1, %c1_i64 : i64
      cc.continue %47 : i64
    } {invariant}
    cc.continue %arg0 : i64
  } step {
  ^bb0(%arg0: i64):
    %44 = arith.addi %arg0, %c1_i64 : i64
    cc.continue %44 : i64
  } {invariant}
  cc.store %c0_i64, %15 : !cc.ptr<i64>
  %20 = cc.load %16 : !cc.ptr<i64>
  %21 = math.absi %20 : i64
  %22 = cc.alloca i64[%21 : i64]
  %23 = cc.alloca i64
  cc.store %c0_i64, %23 : !cc.ptr<i64>
  %24 = cc.loop while ((%arg0 = %c0_i64) -> (i64)) {
    %44 = arith.cmpi slt, %arg0, %20 : i64
    cc.condition %44(%arg0 : i64)
  } do {
  ^bb0(%arg0: i64):
    %44 = cc.load %23 : !cc.ptr<i64>
    %45 = cc.compute_ptr %22[%44] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
    cc.store %44, %45 : !cc.ptr<i64>
    %46 = arith.addi %44, %c1_i64 : i64
    cc.store %46, %23 : !cc.ptr<i64>
    cc.continue %arg0 : i64
  } step {
  ^bb0(%arg0: i64):
    %44 = arith.addi %arg0, %c1_i64 : i64
    cc.continue %44 : i64
  } {invariant}
  %25 = cc.alloca i64[%20 : i64]
  %26 = cc.loop while ((%arg0 = %c0_i64) -> (i64)) {
    %44 = arith.cmpi slt, %arg0, %20 : i64
    cc.condition %44(%arg0 : i64)
  } do {
  ^bb0(%arg0: i64):
    %44 = cc.compute_ptr %25[%arg0] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
    cc.store %c0_i64, %44 : !cc.ptr<i64>
    cc.continue %arg0 : i64
  } step {
  ^bb0(%arg0: i64):
    %44 = arith.addi %arg0, %c1_i64 : i64
    cc.continue %44 : i64
  } {invariant}
  %27 = cc.stdvec_init %25, %20 : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.stdvec<i64>
  %28 = cc.alloca !cc.stdvec<i64>
  cc.store %27, %28 : !cc.ptr<!cc.stdvec<i64>>
  %29 = cc.load %16 : !cc.ptr<i64>
  %30 = math.absi %29 : i64
  %31 = cc.alloca i64[%30 : i64]
  %32 = cc.alloca i64
  cc.store %c0_i64, %32 : !cc.ptr<i64>
  %33 = cc.loop while ((%arg0 = %c0_i64) -> (i64)) {
    %44 = arith.cmpi slt, %arg0, %29 : i64
    cc.condition %44(%arg0 : i64)
  } do {
  ^bb0(%arg0: i64):
    %44 = cc.load %32 : !cc.ptr<i64>
    %45 = cc.compute_ptr %31[%44] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
    cc.store %44, %45 : !cc.ptr<i64>
    %46 = arith.addi %44, %c1_i64 : i64
    cc.store %46, %32 : !cc.ptr<i64>
    cc.continue %arg0 : i64
  } step {
  ^bb0(%arg0: i64):
    %44 = arith.addi %arg0, %c1_i64 : i64
    cc.continue %44 : i64
  } {invariant}
  %34 = cc.alloca i64[%29 : i64]
  %35 = cc.loop while ((%arg0 = %c0_i64) -> (i64)) {
    %44 = arith.cmpi slt, %arg0, %29 : i64
    cc.condition %44(%arg0 : i64)
  } do {
  ^bb0(%arg0: i64):
    %44 = cc.compute_ptr %34[%arg0] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
    cc.store %c0_i64, %44 : !cc.ptr<i64>
    cc.continue %arg0 : i64
  } step {
  ^bb0(%arg0: i64):
    %44 = arith.addi %arg0, %c1_i64 : i64
    cc.continue %44 : i64
  } {invariant}
  %36 = cc.stdvec_init %34, %29 : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.stdvec<i64>
  %37 = cc.alloca !cc.stdvec<i64>
  cc.store %36, %37 : !cc.ptr<!cc.stdvec<i64>>
  %38 = cc.load %14 : !cc.ptr<i64>
  %39 = arith.subi %38, %c1_i64 : i64
  %40 = cc.loop while ((%arg0 = %c0_i64) -> (i64)) {
    %44 = arith.cmpi slt, %arg0, %39 : i64
    cc.condition %44(%arg0 : i64)
  } do {
  ^bb0(%arg0: i64):
    %44 = arith.addi %arg0, %c1_i64 : i64
    %45 = cc.load %14 : !cc.ptr<i64>
    %46 = cc.loop while ((%arg1 = %44) -> (i64)) {
      %47 = arith.cmpi slt, %arg1, %45 : i64
      cc.condition %47(%arg1 : i64)
    } do {
    ^bb0(%arg1: i64):
      %47 = cc.load %15 : !cc.ptr<i64>
      %48 = cc.load %28 : !cc.ptr<!cc.stdvec<i64>>
      %49 = cc.stdvec_data %48 : (!cc.stdvec<i64>) -> !cc.ptr<!cc.array<i64 x ?>>
      %50 = cc.compute_ptr %49[%47] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
      %51 = cc.load %11 : !cc.ptr<!cc.stdvec<i64>>
      %52 = cc.stdvec_data %51 : (!cc.stdvec<i64>) -> !cc.ptr<!cc.array<i64 x ?>>
      %53 = cc.compute_ptr %52[%arg0] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
      %54 = cc.load %53 : !cc.ptr<i64>
      cc.store %54, %50 : !cc.ptr<i64>
      %55 = cc.load %15 : !cc.ptr<i64>
      %56 = cc.load %37 : !cc.ptr<!cc.stdvec<i64>>
      %57 = cc.stdvec_data %56 : (!cc.stdvec<i64>) -> !cc.ptr<!cc.array<i64 x ?>>
      %58 = cc.compute_ptr %57[%55] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
      %59 = cc.load %11 : !cc.ptr<!cc.stdvec<i64>>
      %60 = cc.stdvec_data %59 : (!cc.stdvec<i64>) -> !cc.ptr<!cc.array<i64 x ?>>
      %61 = cc.compute_ptr %60[%arg1] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
      %62 = cc.load %61 : !cc.ptr<i64>
      cc.store %62, %58 : !cc.ptr<i64>
      %63 = cc.load %15 : !cc.ptr<i64>
      %64 = arith.addi %63, %c1_i64 : i64
      cc.store %64, %15 : !cc.ptr<i64>
      cc.continue %arg1 : i64
    } step {
    ^bb0(%arg1: i64):
      %47 = arith.addi %arg1, %c1_i64 : i64
      cc.continue %47 : i64
    } {invariant}
    cc.continue %arg0 : i64
  } step {
  ^bb0(%arg0: i64):
    %44 = arith.addi %arg0, %c1_i64 : i64
    cc.continue %44 : i64
  } {invariant}
  %41 = cc.load %28 : !cc.ptr<!cc.stdvec<i64>>
  %42 = cc.stdvec_size %41 : (!cc.stdvec<i64>) -> i64
  %43 = cc.loop while ((%arg0 = %c0_i64) -> (i64)) {
    %44 = arith.cmpi slt, %arg0, %42 : i64
    cc.condition %44(%arg0 : i64)
  } do {
  ^bb0(%arg0: i64):
    %44 = cc.load %28 : !cc.ptr<!cc.stdvec<i64>>
    %45 = cc.stdvec_data %44 : (!cc.stdvec<i64>) -> !cc.ptr<!cc.array<i64 x ?>>
    %46 = cc.compute_ptr %45[%arg0] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
    %47 = cc.load %46 : !cc.ptr<i64>
    %48 = cc.load %37 : !cc.ptr<!cc.stdvec<i64>>
    %49 = cc.stdvec_data %48 : (!cc.stdvec<i64>) -> !cc.ptr<!cc.array<i64 x ?>>
    %50 = cc.compute_ptr %49[%arg0] : (!cc.ptr<!cc.array<i64 x ?>>, i64) -> !cc.ptr<i64>
    %51 = cc.load %50 : !cc.ptr<i64>
    %52 = cc.alloca i64
    cc.store %47, %52 : !cc.ptr<i64>
    %53 = cc.alloca i64
    cc.store %51, %53 : !cc.ptr<i64>
    %54 = cc.alloca i64
    cc.store %c0_i64, %54 : !cc.ptr<i64>
    %55 = cc.alloca i64
    cc.store %c0_i64, %55 : !cc.ptr<i64>
    %56 = cc.load %52 : !cc.ptr<i64>
    %57 = cc.load %53 : !cc.ptr<i64>
    %58 = arith.cmpi slt, %56, %57 : i64
    cc.if(%58) {
      %62 = cc.load %52 : !cc.ptr<i64>
      cc.store %62, %54 : !cc.ptr<i64>
      %63 = cc.load %53 : !cc.ptr<i64>
      cc.store %63, %55 : !cc.ptr<i64>
    } else {
      %62 = cc.load %52 : !cc.ptr<i64>
      %63 = cc.load %53 : !cc.ptr<i64>
      %64 = arith.cmpi sgt, %62, %63 : i64
      cc.if(%64) {
        %65 = cc.load %53 : !cc.ptr<i64>
        cc.store %65, %54 : !cc.ptr<i64>
        %66 = cc.load %52 : !cc.ptr<i64>
        cc.store %66, %55 : !cc.ptr<i64>
      }
    }
    %59 = cc.load %54 : !cc.ptr<i64>
    %60 = cc.load %55 : !cc.ptr<i64>
    %61 = cc.loop while ((%arg1 = %59) -> (i64)) {
      %62 = arith.cmpi slt, %arg1, %60 : i64
      cc.condition %62(%arg1 : i64)
    } do {
    ^bb0(%arg1: i64):
      %62 = quake.extract_ref %0[%arg1] : (!quake.veq<6>, i64) -> !quake.ref
      %63 = arith.addi %arg1, %c1_i64 : i64
      %64 = quake.extract_ref %0[%63] : (!quake.veq<6>, i64) -> !quake.ref
      quake.x [%62] %64 : (!quake.ref, !quake.ref) -> ()
      cc.continue %arg1 : i64
    } step {
    ^bb0(%arg1: i64):
      %62 = arith.addi %arg1, %c1_i64 : i64
      cc.continue %62 : i64
    } {invariant}
    cc.continue %arg0 : i64
  } step {
  ^bb0(%arg0: i64):
    %44 = arith.addi %arg0, %c1_i64 : i64
    cc.continue %44 : i64
  } {invariant}
  return
}
func.func @__nvqpp__mlirgen__opt(%arg0: !quake.veq<?>, %arg1: i64, %arg2: i64) attributes {"cudaq-kernel"} {
  %c1_i64 = arith.constant 1 : i64
  %c0_i64 = arith.constant 0 : i64
  %0 = cc.alloca i64
  cc.store %arg1, %0 : !cc.ptr<i64>
  %1 = cc.alloca i64
  cc.store %arg2, %1 : !cc.ptr<i64>
  %2 = cc.alloca i64
  cc.store %c0_i64, %2 : !cc.ptr<i64>
  %3 = cc.alloca i64
  cc.store %c0_i64, %3 : !cc.ptr<i64>
  %4 = cc.load %0 : !cc.ptr<i64>
  %5 = cc.load %1 : !cc.ptr<i64>
  %6 = arith.cmpi slt, %4, %5 : i64
  cc.if(%6) {
    %10 = cc.load %0 : !cc.ptr<i64>
    cc.store %10, %2 : !cc.ptr<i64>
    %11 = cc.load %1 : !cc.ptr<i64>
    cc.store %11, %3 : !cc.ptr<i64>
  } else {
    %10 = cc.load %0 : !cc.ptr<i64>
    %11 = cc.load %1 : !cc.ptr<i64>
    %12 = arith.cmpi sgt, %10, %11 : i64
    cc.if(%12) {
      %13 = cc.load %1 : !cc.ptr<i64>
      cc.store %13, %2 : !cc.ptr<i64>
      %14 = cc.load %0 : !cc.ptr<i64>
      cc.store %14, %3 : !cc.ptr<i64>
    }
  }
  %7 = cc.load %2 : !cc.ptr<i64>
  %8 = cc.load %3 : !cc.ptr<i64>
  %9 = cc.loop while ((%arg3 = %7) -> (i64)) {
    %10 = arith.cmpi slt, %arg3, %8 : i64
    cc.condition %10(%arg3 : i64)
  } do {
  ^bb0(%arg3: i64):
    %10 = quake.extract_ref %arg0[%arg3] : (!quake.veq<?>, i64) -> !quake.ref
    %11 = arith.addi %arg3, %c1_i64 : i64
    %12 = quake.extract_ref %arg0[%11] : (!quake.veq<?>, i64) -> !quake.ref
    quake.x [%10] %12 : (!quake.ref, !quake.ref) -> ()
    cc.continue %arg3 : i64
  } step {
  ^bb0(%arg3: i64):
    %10 = arith.addi %arg3, %c1_i64 : i64
    cc.continue %10 : i64
  } {invariant}
  return
}

