// ========================================================================== //
// Copyright (c) 2022 - 2023 NVIDIA Corporation & Affiliates.                 //
// All rights reserved.                                                       //
//                                                                            //
// This source code and the accompanying materials are made available under   //
// the terms of the Apache License 2.0 which accompanies this distribution.   //
// ========================================================================== //

// RUN: cudaq-opt --kernel-execution %s | FileCheck %s

module attributes {quake.mangled_name_map = {__nvqpp__mlirgen__ghz = "_ZN3ghzclEi"}} {

// CHECK-LABEL:   func.func @__nvqpp__mlirgen__ghz(

  func.func @__nvqpp__mlirgen__ghz(%arg0: i32) -> f64 {
    %0 = memref.alloca() : memref<i32>
    memref.store %arg0, %0[] : memref<i32>
    %1 = memref.load %0[] : memref<i32>
    %2 = arith.extsi %1 : i32 to i64
    %3 = quake.alloca !quake.veq<?>[%2 : i64]
    %c0_i32 = arith.constant 0 : i32
    %4 = arith.extsi %c0_i32 : i32 to i64
    %5 = quake.extract_ref %3[%4] : (!quake.veq<?>,i64) -> !quake.ref
    quake.h %5 : (!quake.ref) -> ()
    cc.scope {
      %7 = memref.alloca() : memref<i32>
      memref.store %c0_i32, %7[] : memref<i32>
      %8 = memref.load %7[] : memref<i32>
      %9 = memref.load %0[] : memref<i32>
      %c1_i32 = arith.constant 1 : i32
      %10 = arith.subi %9, %c1_i32 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = memref.load %7[] : memref<i32>
      %13 = arith.index_cast %12 : i32 to index
      cc.loop while ((%arg1 = %13) -> index) {
        %cond = arith.cmpi slt, %arg1, %11 : index
	cc.condition %cond (%arg1 : index)
      } do {
      ^bb1 (%arg11 : index):
        %18 = arith.index_cast %arg11 : index to i64
        %19 = quake.extract_ref %3[%18] : (!quake.veq<?>,i64) -> !quake.ref
        %20 = arith.trunci %18 : i64 to i32
        %21 = arith.addi %20, %c1_i32 : i32
        %22 = arith.extsi %21 : i32 to i64
        %23 = quake.extract_ref %3[%22] : (!quake.veq<?>,i64) -> !quake.ref
        quake.x [%19] %23 : (!quake.ref, !quake.ref) -> ()
	cc.continue %arg11 : index
      } step {
      ^bb2 (%arg21 : index):
        %c1_index = arith.constant 1 : index
        %incr = arith.addi %arg21, %c1_index : index
        cc.continue %incr : index
      }
    }
    %15 = quake.veq_size %3 : (!quake.veq<?>) -> i64
    %16 = arith.index_cast %15 : i64 to index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    cc.loop while ((%argx1 = %c0) -> index) {
        %cond = arith.cmpi slt, %argx1, %16 : index
	cc.condition %cond (%argx1 : index)
    } do {
    ^bb1 (%arg31 : index):
      %18 = quake.extract_ref %3[%arg31] : (!quake.veq<?>,index) -> !quake.ref
      %19 = quake.mz %18 : (!quake.ref) -> i1
      cc.continue %arg31 : index
    } step {
    ^bb1 (%arg32 : index):
      %c1_index = arith.constant 1 : index
      %incr.2 = arith.addi %arg32, %c1_index : index
      cc.continue %incr.2 : index
    }
    %cst = arith.constant 1.000000e+00 : f64
    return %cst : f64
  }
}

// Check the generated code.

// CHECK:         func.func private @altLaunchKernel(!cc.ptr<i8>, !cc.ptr<i8>, !cc.ptr<i8>, i64, i64)
// CHECK:         func.func private @cudaqRegisterKernelName(!cc.ptr<i8>)

// CHECK:         llvm.mlir.global external constant @ghz.kernelName("ghz\00") {addr_space = 0 : i32}

// CHECK-LABEL:   func.func @ghz.thunk(
// CHECK-SAME:                         %[[VAL_0:.*]]: !cc.ptr<i8>,
// CHECK-SAME:                         %[[VAL_1:.*]]: i1) -> !cc.struct<{!cc.ptr<i8>, i64}> {
// CHECK:           %[[VAL_2:.*]] = cc.cast %[[VAL_0]] : (!cc.ptr<i8>) -> !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           %[[VAL_3:.*]] = cc.load %[[VAL_2]] : !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           %[[VAL_4:.*]] = arith.constant 0 : i64
// CHECK:           %[[VAL_5:.*]] = cc.cast %[[VAL_4]] : (i64) -> !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           %[[VAL_6:.*]] = cc.compute_ptr %[[VAL_5]][1] : (!cc.ptr<!cc.struct<{i32, f64}>>) -> !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           %[[VAL_7:.*]] = cc.cast %[[VAL_6]] : (!cc.ptr<!cc.struct<{i32, f64}>>) -> i64
// CHECK:           %[[VAL_8:.*]] = cc.compute_ptr %[[VAL_0]]{{\[}}%[[VAL_7]]] : (!cc.ptr<i8>, i64) -> !cc.ptr<i8>
// CHECK:           %[[VAL_9:.*]] = cc.extract_value %[[VAL_3]][0] : (!cc.struct<{i32, f64}>) -> i32
// CHECK:           %[[VAL_10:.*]] = call @__nvqpp__mlirgen__ghz(%[[VAL_9]]) : (i32) -> f64
// CHECK:           %[[VAL_11:.*]] = cc.compute_ptr %[[VAL_2]][0, 1] : (!cc.ptr<!cc.struct<{i32, f64}>>) -> !cc.ptr<f64>
// CHECK:           cc.store %[[VAL_10]], %[[VAL_11]] : !cc.ptr<f64>
// CHECK:           %[[VAL_12:.*]] = call @__nvqpp_zeroDynamicResult() : () -> !cc.struct<{!cc.ptr<i8>, i64}>
// CHECK:           return %[[VAL_12]] : !cc.struct<{!cc.ptr<i8>, i64}>
// CHECK:         }

// CHECK-LABEL:   func.func @ghz.argsCreator(
// CHECK-SAME:                               %[[VAL_0:.*]]: !cc.ptr<!cc.ptr<i8>>,
// CHECK-SAME:                               %[[VAL_1:.*]]: !cc.ptr<!cc.ptr<i8>>) -> i64 {
// CHECK:           %[[VAL_2:.*]] = cc.undef !cc.struct<{i32, f64}>
// CHECK:           %[[VAL_3:.*]] = arith.constant 0 : i64
// CHECK:           %[[VAL_4:.*]] = cc.compute_ptr %[[VAL_0]][0] : (!cc.ptr<!cc.ptr<i8>>) -> !cc.ptr<!cc.ptr<i8>>
// CHECK:           %[[VAL_5:.*]] = cc.load %[[VAL_4]] : !cc.ptr<!cc.ptr<i8>>
// CHECK:           %[[VAL_6:.*]] = cc.cast %[[VAL_5]] : (!cc.ptr<i8>) -> !cc.ptr<i32>
// CHECK:           %[[VAL_7:.*]] = cc.load %[[VAL_6]] : !cc.ptr<i32>
// CHECK:           %[[VAL_8:.*]] = cc.insert_value %[[VAL_7]], %[[VAL_2]][0] : (!cc.struct<{i32, f64}>, i32) -> !cc.struct<{i32, f64}>
// CHECK:           %[[VAL_9:.*]] = cc.cast %[[VAL_3]] : (i64) -> !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           %[[VAL_10:.*]] = cc.compute_ptr %[[VAL_9]][1] : (!cc.ptr<!cc.struct<{i32, f64}>>) -> !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           %[[VAL_11:.*]] = cc.cast %[[VAL_10]] : (!cc.ptr<!cc.struct<{i32, f64}>>) -> i64
// CHECK:           %[[VAL_12:.*]] = call @malloc(%[[VAL_11]]) : (i64) -> !cc.ptr<i8>
// CHECK:           %[[VAL_13:.*]] = cc.cast %[[VAL_12]] : (!cc.ptr<i8>) -> !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           cc.store %[[VAL_8]], %[[VAL_13]] : !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           cc.store %[[VAL_12]], %[[VAL_1]] : !cc.ptr<!cc.ptr<i8>>
// CHECK:           return %[[VAL_11]] : i64
// CHECK:         }

// CHECK-LABEL:   func.func @_ZN3ghzclEi(
// CHECK-SAME:                           %[[VAL_0:.*]]: !cc.ptr<i8>,
// CHECK-SAME:                           %[[VAL_1:.*]]: i32) -> f64 {
// CHECK:           %[[VAL_2:.*]] = cc.undef !cc.struct<{i32, f64}>
// CHECK:           %[[VAL_3:.*]] = arith.constant 0 : i64
// CHECK:           %[[VAL_4:.*]] = cc.insert_value %[[VAL_1]], %[[VAL_2]][0] : (!cc.struct<{i32, f64}>, i32) -> !cc.struct<{i32, f64}>
// CHECK:           %[[VAL_5:.*]] = cc.cast %[[VAL_3]] : (i64) -> !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           %[[VAL_6:.*]] = cc.compute_ptr %[[VAL_5]][1] : (!cc.ptr<!cc.struct<{i32, f64}>>) -> !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           %[[VAL_7:.*]] = cc.cast %[[VAL_6]] : (!cc.ptr<!cc.struct<{i32, f64}>>) -> i64
// CHECK:           %[[VAL_8:.*]] = arith.addi %[[VAL_7]], %[[VAL_3]] : i64
// CHECK:           %[[VAL_9:.*]] = cc.alloca i8{{\[}}%[[VAL_8]] : i64]
// CHECK:           %[[VAL_10:.*]] = cc.cast %[[VAL_9]] : (!cc.ptr<!cc.array<i8 x ?>>) -> !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           cc.store %[[VAL_4]], %[[VAL_10]] : !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           %[[VAL_11:.*]] = llvm.mlir.addressof @ghz.kernelName : !llvm.ptr<array<4 x i8>>
// CHECK:           %[[VAL_12:.*]] = constant @ghz.thunk : (!cc.ptr<i8>, i1) -> !cc.struct<{!cc.ptr<i8>, i64}>
// CHECK:           %[[VAL_13:.*]] = cc.cast %[[VAL_11]] : (!llvm.ptr<array<4 x i8>>) -> !cc.ptr<i8>
// CHECK:           %[[VAL_14:.*]] = cc.func_ptr %[[VAL_12]] : ((!cc.ptr<i8>, i1) -> !cc.struct<{!cc.ptr<i8>, i64}>) -> !cc.ptr<i8>
// CHECK:           %[[VAL_15:.*]] = cc.cast %[[VAL_10]] : (!cc.ptr<!cc.struct<{i32, f64}>>) -> !cc.ptr<i8>
// CHECK:           %[[VAL_16:.*]] = cc.compute_ptr %[[VAL_5]][0, 1] : (!cc.ptr<!cc.struct<{i32, f64}>>) -> !cc.ptr<!cc.struct<{i32, f64}>>
// CHECK:           %[[VAL_17:.*]] = cc.cast %[[VAL_16]] : (!cc.ptr<!cc.struct<{i32, f64}>>) -> i64
// CHECK:           call @altLaunchKernel(%[[VAL_13]], %[[VAL_14]], %[[VAL_15]], %[[VAL_8]], %[[VAL_17]]) : (!cc.ptr<i8>, !cc.ptr<i8>, !cc.ptr<i8>, i64, i64) -> ()
// CHECK:           %[[VAL_18:.*]] = cc.compute_ptr %[[VAL_10]][0, 1] : (!cc.ptr<!cc.struct<{i32, f64}>>) -> !cc.ptr<f64>
// CHECK:           %[[VAL_19:.*]] = cc.load %[[VAL_18]] : !cc.ptr<f64>
// CHECK:           return %[[VAL_19]] : f64
// CHECK:         }

// CHECK-LABEL:   llvm.func @ghz.kernelRegFunc() {
// CHECK:           %[[VAL_0:.*]] = llvm.mlir.addressof @ghz.kernelName : !llvm.ptr<array<4 x i8>>
// CHECK:           %[[VAL_1:.*]] = cc.cast %[[VAL_0]] : (!llvm.ptr<array<4 x i8>>) -> !cc.ptr<i8>
// CHECK:           func.call @cudaqRegisterKernelName(%[[VAL_1]]) : (!cc.ptr<i8>) -> ()
// CHECK:           %[[VAL_2:.*]] = func.constant @ghz.argsCreator : (!cc.ptr<!cc.ptr<i8>>, !cc.ptr<!cc.ptr<i8>>) -> i64
// CHECK:           %[[VAL_3:.*]] = cc.func_ptr %[[VAL_2]] : ((!cc.ptr<!cc.ptr<i8>>, !cc.ptr<!cc.ptr<i8>>) -> i64) -> !cc.ptr<i8>
// CHECK:           func.call @cudaqRegisterArgsCreator(%[[VAL_1]], %[[VAL_3]]) : (!cc.ptr<i8>, !cc.ptr<i8>) -> ()
// CHECK:           llvm.return
// CHECK:         }

// CHECK:         llvm.mlir.global_ctors {ctors = [@ghz.kernelRegFunc], priorities = [17 : i32]}
