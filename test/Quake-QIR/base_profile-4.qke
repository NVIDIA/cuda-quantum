// ========================================================================== //
// Copyright (c) 2022 - 2023 NVIDIA Corporation & Affiliates.                 //
// All rights reserved.                                                       //
//                                                                            //
// This source code and the accompanying materials are made available under   //
// the terms of the Apache License 2.0 which accompanies this distribution.   //
// ========================================================================== //

// RUN: cudaq-opt %s --add-dealloc | cudaq-translate --convert-to=qir-base | FileCheck %s

// Test base profile lowering without combining quantum allocations.
func.func @sans_combine() {

   %zero = arith.constant 0 : i32
   %one = arith.constant 1 : i32
   %neg = arith.constant -5 : i32
   %two = arith.constant 2 : i32
   %0 = quake.alloca !quake.veq<?>[%two : i32]
  
   %1 = quake.alloca !quake.veq<2>
   
   %qr1 = quake.extract_ref %0[%zero] : (!quake.veq<?>,i32) -> !quake.ref
   %qr2 = quake.extract_ref %1[%one]  : (!quake.veq<2>,i32) -> !quake.ref

   %qr3 = quake.alloca !quake.ref
   %2 = quake.alloca !quake.veq<?>[%one : i32]
   %qr4 = quake.extract_ref %2[0] : (!quake.veq<?>) -> !quake.ref

   %fl1 = arith.constant 0.43 : f64
   %fl2 = arith.constant 0.33 : f64
   %fl3 = arith.constant 0.73 : f64
   quake.h %qr1 : (!quake.ref) -> ()  
   quake.x [%qr1] %qr2 : (!quake.ref, !quake.ref) -> ()
   quake.rx (%fl1) %qr1 : (f64, !quake.ref) -> ()

   quake.h %qr3 : (!quake.ref) -> ()  
   quake.x [%qr3] %qr4 : (!quake.ref, !quake.ref) -> ()
   quake.rx (%fl2) %qr3 : (f64, !quake.ref) -> ()

   quake.h %qr1 : (!quake.ref) -> ()  
   quake.x [%qr1] %qr3 : (!quake.ref, !quake.ref) -> ()
   %qr5 = quake.extract_ref %1[%zero] : (!quake.veq<2>,i32) -> !quake.ref
   quake.rx (%fl3) %qr5 : (f64, !quake.ref) -> ()

   quake.mz %qr1 : (!quake.ref) -> !quake.measure
   quake.mz %qr5 : (!quake.ref) -> !quake.measure
   return 
}

// CHECK-LABEL: define void @sans_combine()
// CHECK:         tail call void @__quantum__qis__h__body(%[[VAL_1:.*]]* null)
// CHECK:         tail call void @__quantum__qis__cnot__body(%[[VAL_1]]* null, %[[VAL_1]]* nonnull inttoptr (i64 3 to %[[VAL_1]]*))
// CHECK:         tail call void @__quantum__qis__rx__body(double 4.300000e-01, %[[VAL_1]]* null)
// CHECK:         tail call void @__quantum__qis__h__body(%[[VAL_1]]* nonnull inttoptr (i64 4 to %[[VAL_1]]*))
// CHECK:         tail call void @__quantum__qis__cnot__body(%[[VAL_1]]* nonnull inttoptr (i64 4 to %[[VAL_1]]*), %[[VAL_1]]* nonnull inttoptr (i64 5 to %[[VAL_1]]*))
// CHECK:         tail call void @__quantum__qis__rx__body(double 3.300000e-01, %[[VAL_1]]* nonnull inttoptr (i64 4 to %[[VAL_1]]*))
// CHECK:         tail call void @__quantum__qis__h__body(%[[VAL_1]]* null)
// CHECK:         tail call void @__quantum__qis__cnot__body(%[[VAL_1]]* null, %[[VAL_1]]* nonnull inttoptr (i64 4 to %[[VAL_1]]*))
// CHECK:         tail call void @__quantum__qis__rx__body(double 7.300000e-01, %[[VAL_1]]* nonnull inttoptr (i64 2 to %[[VAL_1]]*))
// CHECK:         tail call void @__quantum__qis__mz__body(%[[VAL_1]]* null, %[[VAL_2:.*]]* null)
// CHECK:         tail call void @__quantum__qis__mz__body(%[[VAL_1]]* nonnull inttoptr (i64 2 to %[[VAL_1]]*), %[[VAL_2]]* nonnull inttoptr (i64 1 to %[[VAL_2]]*))
// CHECK:         tail call void @__quantum__rt__result_record_output(%[[VAL_2]]* null, i8* nonnull getelementptr inbounds ([7 x i8], [7 x i8]* @cstr.{{.*}}, i64 0, i64 0))
// CHECK:         tail call void @__quantum__rt__result_record_output(%[[VAL_2]]* nonnull inttoptr (i64 1 to %[[VAL_2]]*), i8* nonnull getelementptr inbounds ([7 x i8], [7 x i8]* @cstr.{{.*}}, i64 0, i64 0))
// CHECK:         ret void

