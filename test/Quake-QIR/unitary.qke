// ========================================================================== //
// Copyright (c) 2022 - 2023 NVIDIA Corporation & Affiliates.                 //
// All rights reserved.                                                       //
//                                                                            //
// This source code and the accompanying materials are made available under   //
// the terms of the Apache License 2.0 which accompanies this distribution.   //
// ========================================================================== //

// RUN: cudaq-opt %s | cudaq-translate | FileCheck %s

module {
  func.func @test_constant_unitary() {
    %0 = quake.alloca !quake.ref
    quake.unitary %0 : (!quake.ref) -> () { opName = "custom_h", constantUnitary = [array<f32: 0.707106769, 0.000000e+00>, array<f32: 0.707106769, 0.000000e+00>, array<f32: 0.707106769, 0.000000e+00>, array<f32: -0.707106769, 0.000000e+00>]}
    return 
  }

  func.func @test_runtime_unitary(%arg0 : !cc.stdvec<complex<f64>>) {
    %0 = quake.alloca !quake.ref
    quake.unitary %0 (%arg0) :  (!quake.ref, !cc.stdvec<complex<f64>>) -> () {opName = "givens"}
    return
  }
}

// CHECK-LABEL:   define void @test_constant_unitary
// CHECK:         %[[VAL_0:.*]] = tail call
// CHECK:         %[[VAL_1:.*]]* @__quantum__rt__qubit_allocate_array(i64 1)
// CHECK:         %[[VAL_2:.*]] = tail call i8* @__quantum__rt__array_get_element_ptr_1d(%[[VAL_1]]* %[[VAL_0]], i64 0)
// CHECK:         %[[VAL_3:.*]] = bitcast i8* %[[VAL_2]] to i8**
// CHECK:         %[[VAL_4:.*]] = load i8*, i8** %[[VAL_3]], align 8
// CHECK:         %[[VAL_5:.*]] = tail call %[[VAL_1]]* @__quantum__rt__array_create_1d(i32 8, i64 1)
// CHECK:         %[[VAL_6:.*]] = tail call i8* @__quantum__rt__array_get_element_ptr_1d(%[[VAL_1]]* %[[VAL_5]], i64 0)
// CHECK:         %[[VAL_7:.*]] = bitcast i8* %[[VAL_6]] to i8**
// CHECK:         store i8* %[[VAL_4]], i8** %[[VAL_7]], align 8
// CHECK:         %[[VAL_8:.*]] = tail call %[[VAL_1]]* @__quantum__rt__array_create_1d(i32 8, i64 0)
// CHECK:         tail call void @__quantum__qis__constant_unitary(double* getelementptr (<4 x double>, <4 x double>* @custom_h_real, i64 0, i64 0), double* getelementptr (<4 x double>, <4 x double>* @custom_h_imag, i64 0, i64 0), %[[VAL_1]]* %[[VAL_8]], %[[VAL_1]]* %[[VAL_5]])
// CHECK:         tail call void @__quantum__rt__qubit_release_array(%[[VAL_1]]* %[[VAL_0]])
// CHECK:         ret void

// CHECK-LABEL:   define void @test_runtime_unitary
// CHECK:         %[[VAL_0:.*]] = tail call
// CHECK:         %[[VAL_1:.*]]* @__quantum__rt__qubit_allocate_array(i64 1)
// CHECK:         %[[VAL_2:.*]] = tail call i8* @__quantum__rt__array_get_element_ptr_1d(%[[VAL_1]]* %[[VAL_0]], i64 0)
// CHECK:         %[[VAL_3:.*]] = bitcast i8* %[[VAL_2]] to i8**
// CHECK:         %[[VAL_4:.*]] = load i8*, i8** %[[VAL_3]], align 8
// CHECK:         %[[VAL_5:.*]] = tail call %[[VAL_1]]* @__quantum__rt__array_create_1d(i32 8, i64 1)
// CHECK:         %[[VAL_6:.*]] = tail call i8* @__quantum__rt__array_get_element_ptr_1d(%[[VAL_1]]* %[[VAL_5]], i64 0)
// CHECK:         %[[VAL_7:.*]] = bitcast i8* %[[VAL_6]] to i8**
// CHECK:         store i8* %[[VAL_4]], i8** %[[VAL_7]], align 8
// CHECK:         %[[VAL_8:.*]] = tail call %[[VAL_1]]* @__quantum__rt__array_create_1d(i32 8, i64 0)
// CHECK:         tail call void @__quantum__qis__unitary({ { double, double }*, i64 } %[[VAL_9:.*]], %[[VAL_1]]* %[[VAL_8]], %[[VAL_1]]* %[[VAL_5]])
// CHECK:         tail call void @__quantum__rt__qubit_release_array(%[[VAL_1]]* %[[VAL_0]])
// CHECK:         ret void