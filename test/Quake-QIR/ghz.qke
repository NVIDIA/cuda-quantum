// ========================================================================== //
// Copyright (c) 2022 - 2023 NVIDIA Corporation & Affiliates.                 //
// All rights reserved.                                                       //
//                                                                            //
// This source code and the accompanying materials are made available under   //
// the terms of the Apache License 2.0 which accompanies this distribution.   //
// ========================================================================== //

// RUN: cudaq-opt %s --canonicalize --quake-add-deallocs | cudaq-translate --convert-to=qir | FileCheck %s
module {
// CHECK:    %[[VAL_0:.*]] = zext i32
// CHECK:    %[[VAL_1:.*]] to i64
// CHECK:         %[[VAL_2:.*]] = tail call %[[VAL_3:.*]]* @__quantum__rt__qubit_allocate_array(i64 %[[VAL_0]])
// CHECK:         %[[VAL_4:.*]] = tail call i8* @__quantum__rt__array_get_element_ptr_1d(%[[VAL_3]]* %[[VAL_2]], i64 0)
// CHECK:         %[[VAL_5:.*]] = bitcast i8* %[[VAL_4]] to %[[VAL_6:.*]]**
// CHECK:         %[[VAL_7:.*]] = load %[[VAL_6]]*, %[[VAL_6]]** %[[VAL_5]], align 8
// CHECK:         tail call void @__quantum__qis__h(%[[VAL_6]]* %[[VAL_7]])
// CHECK:         %[[VAL_8:.*]] = add i32 %[[VAL_1]], -1
// CHECK:         %[[VAL_9:.*]] = sext i32 %[[VAL_8]] to i64
// CHECK:         %[[VAL_10:.*]] = icmp sgt i32 %[[VAL_8]], 0
// CHECK:         br i1 %[[VAL_10]], label %[[VAL_11:.*]], label %[[VAL_12:[^,]*]]
// CHECK:       .lr.ph:
// CHECK-SAME:  ; preds = %[[VAL_13:.*]], %[[VAL_11]]
// CHECK:         %[[VAL_14:.*]] = phi i64 [ %[[VAL_15:.*]], %[[VAL_11]] ], [ 0, %[[VAL_13]] ]
// CHECK:         %[[VAL_15]] = add nuw nsw i64 %[[VAL_14]], 1
// CHECK:         %[[VAL_16:.*]] = tail call i8* @__quantum__rt__array_get_element_ptr_1d(%[[VAL_3]]* %[[VAL_2]], i64 %[[VAL_14]])
// CHECK:         %[[VAL_17:.*]] = bitcast i8* %[[VAL_16]] to %[[VAL_6]]**
// CHECK:         %[[VAL_18:.*]] = load %[[VAL_6]]*, %[[VAL_6]]** %[[VAL_17]], align 8
// CHECK:         %[[VAL_19:.*]] = tail call i8* @__quantum__rt__array_get_element_ptr_1d(%[[VAL_3]]* %[[VAL_2]], i64 %[[VAL_15]])
// CHECK:         %[[VAL_20:.*]] = bitcast i8* %[[VAL_19]] to %[[VAL_6]]**
// CHECK:         %[[VAL_21:.*]] = load %[[VAL_6]]*, %[[VAL_6]]** %[[VAL_20]], align 8
// CHECK: tail call void (i64, void (%Array*, %Qubit*)*, ...) @invokeWithControlQubits(i64 1, void (%Array*, %Qubit*)* nonnull @__quantum__qis__x__ctl, %Qubit* %[[VAL_18]], %Qubit* %[[VAL_21]])
// CHECK:         %[[VAL_22:.*]] = icmp eq i64 %[[VAL_15]], %[[VAL_9]]
// CHECK:         br i1 %[[VAL_22]], label %[[VAL_12]], label %[[VAL_11]]
// CHECK:       ._crit_edge:
// CHECK-SAME:  ; preds = %[[VAL_11]], %[[VAL_13]]
// CHECK:         tail call void @__quantum__rt__qubit_release_array(%[[VAL_3]]* %[[VAL_2]])
// CHECK:         ret void
    func.func @ghz(%arg0 : i32) {
        %c0 = arith.constant 0 : i32
        %one = arith.constant 1 : i32
        %q = quake.alloca !quake.veq<?>[%arg0 : i32]
        %q0 = quake.extract_ref %q [%c0] : (!quake.veq<?>,i32) -> !quake.ref
        quake.h %q0 : (!quake.ref) -> ()
        %size_m_1 = arith.subi %arg0, %one : i32
        %upper = arith.index_cast %size_m_1 : i32 to index
        affine.for %i = 0 to %upper {
            %i_int = arith.index_cast %i : index to i32
            %ip1 = arith.addi %i_int, %one : i32
            %qi = quake.extract_ref %q [%i] : (!quake.veq<?>,index) -> !quake.ref
            %qi1 = quake.extract_ref %q [%ip1] : (!quake.veq<?>,i32) -> !quake.ref
            quake.x [%qi] %qi1 : (!quake.ref,!quake.ref) -> ()
        }
        return
    }
}
